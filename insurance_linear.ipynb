{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-insurance-linear.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b581cde0f3a944cf8786216e7c84f94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1187043df8b7418bbb9d17b7e6501661",
              "IPY_MODEL_bd7c5b3a54c74323b09bc5046c35fb27"
            ],
            "layout": "IPY_MODEL_b65c94728dfe47b88b995d9871b2e638"
          }
        },
        "b65c94728dfe47b88b995d9871b2e638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1187043df8b7418bbb9d17b7e6501661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdbb4373000a4c19a114fe5f07e57a81",
            "max": 55628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1749146c4c645d88d957829e8f6fa66",
            "value": 55628
          }
        },
        "bd7c5b3a54c74323b09bc5046c35fb27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e998679d085a449b9130fb838b4ac02a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_edbb4ea736f949be922e8e363bb15054",
            "value": " 56320/? [01:29&lt;00:00, 626.24it/s]"
          }
        },
        "d1749146c4c645d88d957829e8f6fa66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "cdbb4373000a4c19a114fe5f07e57a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edbb4ea736f949be922e8e363bb15054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e998679d085a449b9130fb838b4ac02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "nt8w-xhDaosP"
      },
      "source": [
        "# Insurance cost prediction using linear regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnzcyQkBaosQ"
      },
      "source": [
        "import torch\n",
        "import jovian\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdeRfJ_1aosR"
      },
      "source": [
        "project_name='02-insurance-linear-regression' # will be used by jovian.commit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqIS1e0laosR"
      },
      "source": [
        "## Step 1: Download and explore the data\n",
        "\n",
        "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "b581cde0f3a944cf8786216e7c84f94e",
            "b65c94728dfe47b88b995d9871b2e638",
            "1187043df8b7418bbb9d17b7e6501661",
            "bd7c5b3a54c74323b09bc5046c35fb27",
            "d1749146c4c645d88d957829e8f6fa66",
            "cdbb4373000a4c19a114fe5f07e57a81",
            "edbb4ea736f949be922e8e363bb15054",
            "e998679d085a449b9130fb838b4ac02a"
          ]
        },
        "id": "KyOMO-IlaosR",
        "outputId": "0bff68ac-70cc-464d-ae6c-b3d1a48eee9c"
      },
      "source": [
        "DATASET_URL = \"https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv\"\n",
        "DATA_FILENAME = \"insurance.csv\"\n",
        "download_url(DATASET_URL, '.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://hub.jovian.ml/wp-content/uploads/2020/05/insurance.csv to ./insurance.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b581cde0f3a944cf8786216e7c84f94e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=55628.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTmwhOTbaosS"
      },
      "source": [
        "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HarhAvFPaosS",
        "outputId": "cb029d3f-09c3-4378-d3ca-44c56a2b142e"
      },
      "source": [
        "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
        "dataframe_raw.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrOV7LaXaosT"
      },
      "source": [
        "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hvifw5PaosT"
      },
      "source": [
        "your_name = 'nouman' # at least 5 characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09E1wYYoaosT"
      },
      "source": [
        "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Ri-O39aosT"
      },
      "source": [
        "def customize_dataset(dataframe_raw, rand_str):\n",
        "    dataframe = dataframe_raw.copy(deep=True)\n",
        "    # drop some rows\n",
        "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
        "    # scale input\n",
        "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
        "    # scale target\n",
        "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
        "    # drop column\n",
        "    if ord(rand_str[3]) % 2 == 1:\n",
        "        dataframe = dataframe.drop(['region'], axis=1)\n",
        "    return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_6XDn0tgaosU",
        "outputId": "d20271ad-2829-4d51-bddb-340730a684ac"
      },
      "source": [
        "dataframe = customize_dataset(dataframe_raw, your_name)\n",
        "dataframe.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>46</td>\n",
              "      <td>female</td>\n",
              "      <td>31.1355</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>9632.724075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1217</th>\n",
              "      <td>29</td>\n",
              "      <td>male</td>\n",
              "      <td>41.3919</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>4747.995837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>837</th>\n",
              "      <td>56</td>\n",
              "      <td>female</td>\n",
              "      <td>31.4241</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>13639.531113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1082</th>\n",
              "      <td>38</td>\n",
              "      <td>male</td>\n",
              "      <td>22.1445</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>6851.405925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>49.6947</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>10598.714451</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex      bmi  children smoker       charges\n",
              "538    46  female  31.1355         1     no   9632.724075\n",
              "1217   29    male  41.3919         2     no   4747.995837\n",
              "837    56  female  31.4241         0     no  13639.531113\n",
              "1082   38    male  22.1445         1     no   6851.405925\n",
              "563    50    male  49.6947         1     no  10598.714451"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVdoUCeYaosU"
      },
      "source": [
        "Let us answer some basic questions about the dataset. \n",
        "\n",
        "\n",
        "**Q: How many rows does the dataset have?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Wxd19eXaosV",
        "outputId": "b1411964-a672-469b-9087-39f26d5226e9"
      },
      "source": [
        "num_rows = dataframe.shape[0]\n",
        "print(num_rows)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XXiBQkCaosV"
      },
      "source": [
        "**Q: How many columns doe the dataset have**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCf5zxzwaosV",
        "outputId": "b0bb5445-6ab3-409e-9ca8-c6ef6e75a4d4"
      },
      "source": [
        "num_cols = dataframe.shape[1]\n",
        "print(num_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A9soNXPaosV"
      },
      "source": [
        "**Q: What are the column titles of the input variables?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hfjqsCMaosV",
        "outputId": "8e3c4ad6-a1a2-46a2-a0d1-017569e018b4"
      },
      "source": [
        "input_cols = dataframe.columns[0:5]\n",
        "(input_cols)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'sex', 'bmi', 'children', 'smoker'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-oLZPPTaosV"
      },
      "source": [
        "**Q: Which of the input columns are non-numeric or categorial variables ?**\n",
        "\n",
        "Hint: `sex` is one of them. List the columns that are not numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T74Pq8gaosW",
        "outputId": "c125024f-92c1-4d20-a70c-597262d5f92c"
      },
      "source": [
        "categorical_cols = ['smoker', 'sex']\n",
        "categorical_cols"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['smoker', 'sex']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_vvPi44aosW"
      },
      "source": [
        "**Q: What are the column titles of output/target variable(s)?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0BkqdR8aosW"
      },
      "source": [
        "output_cols = ['charges']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSOCDdinaosX"
      },
      "source": [
        "Remember to commit your notebook to Jovian after every step, so that you don't lose your work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP5ZJ2rmaosX"
      },
      "source": [
        "!pip install jovian --upgrade -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5h76QiLaosX"
      },
      "source": [
        "import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeMvxqyHaosX",
        "outputId": "b71b1bcc-8a09-4ae5-9399-e2f3ef50b05f"
      },
      "source": [
        "jovian.commit()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Please enter your API key ( from https://jovian.ai/ ):\u001b[0m\n",
            "API KEY:"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3dcBaJKaosY"
      },
      "source": [
        "## Step 2: Prepare the dataset for training\n",
        "\n",
        "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN_gPZwjaosY"
      },
      "source": [
        "def dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    targets_array = dataframe1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh8fu3oGaosY"
      },
      "source": [
        "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUv8GX09aosY",
        "outputId": "77a871fc-95ca-4a99-fd51-4aa846809c7f"
      },
      "source": [
        "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
        "inputs_array.shape, inputs_array, targets_array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1271, 5), array([[46.     ,  0.     , 31.1355 ,  1.     ,  0.     ],\n",
              "        [29.     ,  1.     , 41.3919 ,  2.     ,  0.     ],\n",
              "        [56.     ,  0.     , 31.4241 ,  0.     ,  0.     ],\n",
              "        ...,\n",
              "        [46.     ,  0.     , 22.1445 ,  2.     ,  0.     ],\n",
              "        [63.     ,  1.     , 45.87075,  3.     ,  0.     ],\n",
              "        [60.     ,  0.     , 31.857  ,  1.     ,  0.     ]]), array([[ 9632.724075 ],\n",
              "        [ 4747.995837 ],\n",
              "        [13639.531113 ],\n",
              "        ...,\n",
              "        [10756.791045 ],\n",
              "        [18199.5708375],\n",
              "        [15472.89081  ]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnM6UsjIaosY"
      },
      "source": [
        "**Q: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnnODzO_aosZ"
      },
      "source": [
        "inputs = torch.from_numpy(inputs_array).type(torch.float32)\n",
        "targets = torch.from_numpy(targets_array).type(torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFzVyFmMaosZ",
        "outputId": "845db6aa-e4ce-4455-bfec-554a792caceb"
      },
      "source": [
        "inputs.dtype, targets.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdOCJwVraosZ"
      },
      "source": [
        "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVz53DACaosZ"
      },
      "source": [
        "dataset = TensorDataset(inputs, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MclWyNUaosZ"
      },
      "source": [
        "**Q: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKeImEdbaosZ"
      },
      "source": [
        "val_percent = 0.2 # between 0.1 and 0.2\n",
        "val_size = int(num_rows * val_percent)\n",
        "train_size = num_rows - val_size\n",
        "\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size,val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y6jYebgaosZ"
      },
      "source": [
        "Finally, we can create data loaders for training & validation.\n",
        "\n",
        "**Q: Pick a batch size for the data loader.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGAAsZvIaosa"
      },
      "source": [
        "batch_size = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzEJRCuEaosa"
      },
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc5KOvXcaosa"
      },
      "source": [
        "Let's look at a batch of data to verify everything is working fine so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyGNYCfnaosa",
        "outputId": "69d877a6-d53d-439d-d8f0-9c35898e6389"
      },
      "source": [
        "for xb, yb in train_loader:\n",
        "    print(\"inputs:\", xb)\n",
        "    print(\"targets:\", yb)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[34.0000,  1.0000, 37.9731,  0.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 25.7631,  0.0000,  0.0000],\n",
            "        [55.0000,  1.0000, 36.3802,  0.0000,  0.0000],\n",
            "        [20.0000,  1.0000, 31.1077,  1.0000,  1.0000],\n",
            "        [18.0000,  0.0000, 34.5543,  0.0000,  0.0000],\n",
            "        [61.0000,  1.0000, 37.2239,  0.0000,  0.0000],\n",
            "        [35.0000,  1.0000, 19.8246,  1.0000,  0.0000],\n",
            "        [49.0000,  0.0000, 47.3748,  2.0000,  0.0000],\n",
            "        [44.0000,  0.0000, 42.2466,  0.0000,  1.0000],\n",
            "        [19.0000,  1.0000, 37.8510,  0.0000,  0.0000],\n",
            "        [55.0000,  1.0000, 42.4908,  0.0000,  0.0000],\n",
            "        [33.0000,  1.0000, 30.4750,  2.0000,  0.0000],\n",
            "        [55.0000,  1.0000, 39.1219,  1.0000,  0.0000],\n",
            "        [29.0000,  1.0000, 32.1623,  1.0000,  0.0000],\n",
            "        [44.0000,  1.0000, 34.0659,  2.0000,  0.0000],\n",
            "        [29.0000,  1.0000, 41.3919,  2.0000,  0.0000],\n",
            "        [40.0000,  1.0000, 27.8388,  0.0000,  0.0000],\n",
            "        [57.0000,  1.0000, 46.7643,  1.0000,  1.0000],\n",
            "        [51.0000,  0.0000, 40.3873,  3.0000,  0.0000],\n",
            "        [20.0000,  1.0000, 36.9963,  0.0000,  0.0000],\n",
            "        [30.0000,  1.0000, 43.1013,  1.0000,  0.0000],\n",
            "        [35.0000,  0.0000, 30.7470,  3.0000,  0.0000],\n",
            "        [20.0000,  0.0000, 31.9513,  0.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 25.9740,  2.0000,  0.0000],\n",
            "        [44.0000,  1.0000, 30.4140,  2.0000,  0.0000],\n",
            "        [62.0000,  1.0000, 35.5367,  0.0000,  1.0000],\n",
            "        [33.0000,  0.0000, 39.4383,  0.0000,  1.0000],\n",
            "        [57.0000,  0.0000, 33.8494,  0.0000,  0.0000],\n",
            "        [61.0000,  0.0000, 43.4010,  2.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 31.4241,  1.0000,  0.0000],\n",
            "        [36.0000,  1.0000, 39.0720,  1.0000,  1.0000],\n",
            "        [42.0000,  1.0000, 39.9267,  2.0000,  0.0000],\n",
            "        [54.0000,  0.0000, 32.0568,  2.0000,  0.0000],\n",
            "        [26.0000,  0.0000, 44.6054,  0.0000,  0.0000],\n",
            "        [57.0000,  1.0000, 44.7108,  0.0000,  0.0000],\n",
            "        [39.0000,  1.0000, 32.8560,  4.0000,  0.0000],\n",
            "        [49.0000,  0.0000, 38.5947,  1.0000,  0.0000],\n",
            "        [58.0000,  0.0000, 27.9720,  0.0000,  0.0000],\n",
            "        [27.0000,  0.0000, 23.8317,  0.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 33.7440,  3.0000,  0.0000],\n",
            "        [23.0000,  0.0000, 34.8540,  0.0000,  1.0000],\n",
            "        [27.0000,  0.0000, 26.7510,  0.0000,  0.0000],\n",
            "        [37.0000,  0.0000, 30.7914,  3.0000,  0.0000],\n",
            "        [22.0000,  0.0000, 34.4322,  3.0000,  1.0000],\n",
            "        [46.0000,  0.0000, 53.3577,  2.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 31.7460,  5.0000,  0.0000],\n",
            "        [34.0000,  1.0000, 46.7643,  2.0000,  0.0000],\n",
            "        [43.0000,  0.0000, 51.2820,  0.0000,  1.0000],\n",
            "        [59.0000,  0.0000, 26.2570,  0.0000,  1.0000],\n",
            "        [44.0000,  1.0000, 28.1551,  1.0000,  0.0000],\n",
            "        [19.0000,  0.0000, 41.5473,  0.0000,  0.0000],\n",
            "        [27.0000,  0.0000, 34.8540,  0.0000,  1.0000],\n",
            "        [44.0000,  0.0000, 48.7179,  2.0000,  1.0000],\n",
            "        [18.0000,  1.0000, 31.6350,  0.0000,  0.0000],\n",
            "        [55.0000,  0.0000, 39.0720,  0.0000,  1.0000],\n",
            "        [18.0000,  0.0000, 44.6054,  0.0000,  0.0000],\n",
            "        [45.0000,  0.0000, 30.6859,  1.0000,  0.0000],\n",
            "        [49.0000,  1.0000, 24.9916,  0.0000,  0.0000],\n",
            "        [32.0000,  1.0000, 31.2132,  4.0000,  1.0000],\n",
            "        [56.0000,  0.0000, 30.1920,  0.0000,  0.0000],\n",
            "        [62.0000,  0.0000, 36.8520,  0.0000,  0.0000],\n",
            "        [44.0000,  0.0000, 35.8974,  1.0000,  0.0000],\n",
            "        [45.0000,  1.0000, 23.7262,  0.0000,  0.0000],\n",
            "        [22.0000,  0.0000, 39.9600,  0.0000,  0.0000],\n",
            "        [27.0000,  1.0000, 34.5543,  1.0000,  1.0000],\n",
            "        [40.0000,  0.0000, 32.5230,  4.0000,  0.0000],\n",
            "        [37.0000,  1.0000, 34.2713,  3.0000,  0.0000],\n",
            "        [26.0000,  0.0000, 25.0971,  0.0000,  0.0000],\n",
            "        [29.0000,  1.0000, 30.1920,  0.0000,  0.0000],\n",
            "        [63.0000,  1.0000, 40.8092,  0.0000,  0.0000],\n",
            "        [23.0000,  0.0000, 31.0800,  0.0000,  0.0000],\n",
            "        [47.0000,  1.0000, 52.7472,  1.0000,  0.0000],\n",
            "        [63.0000,  0.0000, 29.9478,  0.0000,  1.0000],\n",
            "        [52.0000,  0.0000, 34.2713,  0.0000,  0.0000],\n",
            "        [27.0000,  0.0000, 34.6931,  1.0000,  0.0000],\n",
            "        [41.0000,  0.0000, 35.0760,  0.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 30.2642,  2.0000,  0.0000],\n",
            "        [54.0000,  0.0000, 34.1880,  3.0000,  0.0000],\n",
            "        [25.0000,  1.0000, 28.5714,  0.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 35.4312,  0.0000,  1.0000],\n",
            "        [44.0000,  1.0000, 33.5220,  2.0000,  1.0000],\n",
            "        [19.0000,  1.0000, 19.4028,  0.0000,  0.0000],\n",
            "        [57.0000,  0.0000, 28.5714,  2.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 30.6360,  0.0000,  0.0000],\n",
            "        [52.0000,  1.0000, 38.2784,  3.0000,  1.0000],\n",
            "        [62.0000,  1.0000, 41.5140,  0.0000,  0.0000],\n",
            "        [52.0000,  1.0000, 36.3802,  3.0000,  0.0000],\n",
            "        [49.0000,  1.0000, 34.7985,  1.0000,  0.0000],\n",
            "        [58.0000,  0.0000, 35.3257,  2.0000,  0.0000],\n",
            "        [27.0000,  0.0000, 27.9443,  0.0000,  0.0000],\n",
            "        [29.0000,  1.0000, 43.2234,  1.0000,  0.0000],\n",
            "        [26.0000,  1.0000, 30.2642,  3.0000,  0.0000],\n",
            "        [63.0000,  1.0000, 38.9499,  0.0000,  1.0000],\n",
            "        [19.0000,  1.0000, 38.1840,  0.0000,  0.0000],\n",
            "        [59.0000,  1.0000, 45.6654,  1.0000,  1.0000],\n",
            "        [35.0000,  1.0000, 30.7914,  2.0000,  1.0000],\n",
            "        [18.0000,  1.0000, 24.1758,  2.0000,  0.0000],\n",
            "        [34.0000,  0.0000, 21.0900,  3.0000,  0.0000],\n",
            "        [21.0000,  0.0000, 29.3040,  1.0000,  0.0000],\n",
            "        [43.0000,  0.0000, 29.8424,  0.0000,  1.0000]])\n",
            "targets: tensor([[ 4604.1606],\n",
            "        [ 1312.5924],\n",
            "        [12403.9102],\n",
            "        [20545.6445],\n",
            "        [ 1897.6028],\n",
            "        [15377.7041],\n",
            "        [ 5986.3057],\n",
            "        [11467.0391],\n",
            "        [57195.6094],\n",
            "        [ 1475.8871],\n",
            "        [11964.7529],\n",
            "        [ 6155.9194],\n",
            "        [13331.0566],\n",
            "        [ 4727.4531],\n",
            "        [ 9045.7695],\n",
            "        [ 4747.9956],\n",
            "        [ 6336.3237],\n",
            "        [56950.3555],\n",
            "        [13380.9834],\n",
            "        [ 1628.0886],\n",
            "        [22186.9121],\n",
            "        [ 7504.5884],\n",
            "        [ 2874.9370],\n",
            "        [ 3408.8757],\n",
            "        [ 9040.4189],\n",
            "        [53480.9414],\n",
            "        [64508.4219],\n",
            "        [13853.7070],\n",
            "        [16655.0352],\n",
            "        [13188.6279],\n",
            "        [45289.7344],\n",
            "        [ 8377.5869],\n",
            "        [14153.0820],\n",
            "        [ 3745.4568],\n",
            "        [24229.5547],\n",
            "        [ 8789.3525],\n",
            "        [11213.1553],\n",
            "        [13849.4775],\n",
            "        [ 3923.5603],\n",
            "        [ 4073.7856],\n",
            "        [39974.5391],\n",
            "        [ 3479.7275],\n",
            "        [ 8519.3613],\n",
            "        [41646.8398],\n",
            "        [11036.5225],\n",
            "        [ 5484.7227],\n",
            "        [ 5995.3008],\n",
            "        [53659.9492],\n",
            "        [30044.1699],\n",
            "        [ 8796.0898],\n",
            "        [ 2501.5427],\n",
            "        [40761.4805],\n",
            "        [54055.1523],\n",
            "        [ 2003.3055],\n",
            "        [51975.8477],\n",
            "        [ 2594.4390],\n",
            "        [33158.0195],\n",
            "        [10165.9648],\n",
            "        [25122.8008],\n",
            "        [12955.6162],\n",
            "        [15751.1484],\n",
            "        [ 8931.4531],\n",
            "        [ 8450.6602],\n",
            "        [ 2535.0764],\n",
            "        [40723.5664],\n",
            "        [18519.7207],\n",
            "        [ 7952.3301],\n",
            "        [ 3716.8745],\n",
            "        [ 3353.3264],\n",
            "        [16358.7646],\n",
            "        [15358.2129],\n",
            "        [ 9458.1865],\n",
            "        [33872.0508],\n",
            "        [26963.3125],\n",
            "        [ 4628.6035],\n",
            "        [ 7237.7686],\n",
            "        [26317.5820],\n",
            "        [14163.2246],\n",
            "        [ 2501.0547],\n",
            "        [39487.8398],\n",
            "        [45628.2969],\n",
            "        [ 1896.9680],\n",
            "        [14776.1240],\n",
            "        [ 1465.3162],\n",
            "        [70225.0391],\n",
            "        [15185.8486],\n",
            "        [13208.2578],\n",
            "        [10869.4629],\n",
            "        [15920.6211],\n",
            "        [ 4163.5854],\n",
            "        [ 4061.5493],\n",
            "        [ 5453.7051],\n",
            "        [55054.9727],\n",
            "        [ 1476.3750],\n",
            "        [57295.1914],\n",
            "        [24551.3887],\n",
            "        [13904.3369],\n",
            "        [ 7901.0547],\n",
            "        [ 3039.4014],\n",
            "        [25475.9570]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oE36WYNaosa"
      },
      "source": [
        "Let's save our work by committing to Jovian."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "0f9mwloTaosa",
        "outputId": "a10a0fd2-3895-46e7-a79e-57690be376af"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/noumanamir453/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/noumanamir453/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSfVn_EQaosa"
      },
      "source": [
        "## Step 3: Create a Linear Regression Model\n",
        "\n",
        "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4VXKUc3aosa"
      },
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGloeg1uaosb"
      },
      "source": [
        "**Q: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
        "\n",
        "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_T6Joi2aosb"
      },
      "source": [
        "class InsuranceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)                  # fill this (hint: use input_size & output_size defined above)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)                        # fill this\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs)          \n",
        "        # Calcuate loss\n",
        "        loss = F.l1_loss(out, targets)                # fill this\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        loss = loss = F.l1_loss(out, targets)                            # fill this    \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ODwoT0aosb"
      },
      "source": [
        "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBUWlf9Jaosb"
      },
      "source": [
        "model = InsuranceModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQWlVKcKaosc"
      },
      "source": [
        "Let's check out the weights and biases of the model using `model.parameters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AUFGQkCaosc",
        "outputId": "87d337b0-6ccc-4870-a67a-909726bbb760"
      },
      "source": [
        "list(model.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.1089, -0.3771,  0.2057,  0.4306, -0.1588]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.4260], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jZ1r0Jmaosc"
      },
      "source": [
        "One final commit before we train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "-7smueXCaosc",
        "outputId": "e3525fce-1d09-426b-c9f7-2599b1791fa9"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/noumanamir453/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/noumanamir453/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I3OVOdWaosc"
      },
      "source": [
        "## Step 4: Train the model to fit the data\n",
        "\n",
        "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGpekb1qaosc"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WzOgF68aosd"
      },
      "source": [
        "**Q: Use the `evaluate` function to calculate the loss on the validation set before training.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LMv0y1Caosd",
        "outputId": "cc8047ba-0e5f-4229-ea35-1af3e72a3e03"
      },
      "source": [
        "result = evaluate(model, val_loader) # Use the the evaluate function\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'val_loss': 14452.15625}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9hlsvWGaose"
      },
      "source": [
        "\n",
        "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYZVpy9Gaose"
      },
      "source": [
        "**Q: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
        "\n",
        "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jV_eL1_aose",
        "outputId": "e22147e5-ac85-4ac7-9704-842d30bef16d"
      },
      "source": [
        "epochs = 1000\n",
        "lr = 2e-1\n",
        "history1 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 7319.7539\n",
            "Epoch [40], val_loss: 7129.5098\n",
            "Epoch [60], val_loss: 7121.5366\n",
            "Epoch [80], val_loss: 7105.4390\n",
            "Epoch [100], val_loss: 7098.9023\n",
            "Epoch [120], val_loss: 7094.6851\n",
            "Epoch [140], val_loss: 7094.0078\n",
            "Epoch [160], val_loss: 7103.9043\n",
            "Epoch [180], val_loss: 7081.8970\n",
            "Epoch [200], val_loss: 7074.4917\n",
            "Epoch [220], val_loss: 7067.9937\n",
            "Epoch [240], val_loss: 7085.2788\n",
            "Epoch [260], val_loss: 7059.6562\n",
            "Epoch [280], val_loss: 7055.6714\n",
            "Epoch [300], val_loss: 7056.5195\n",
            "Epoch [320], val_loss: 7048.4727\n",
            "Epoch [340], val_loss: 7051.7578\n",
            "Epoch [360], val_loss: 7039.9937\n",
            "Epoch [380], val_loss: 7042.7754\n",
            "Epoch [400], val_loss: 7062.8335\n",
            "Epoch [420], val_loss: 7029.9136\n",
            "Epoch [440], val_loss: 7027.0757\n",
            "Epoch [460], val_loss: 7026.2671\n",
            "Epoch [480], val_loss: 7035.1479\n",
            "Epoch [500], val_loss: 7016.8267\n",
            "Epoch [520], val_loss: 7023.6831\n",
            "Epoch [540], val_loss: 7010.2104\n",
            "Epoch [560], val_loss: 7008.4585\n",
            "Epoch [580], val_loss: 7021.5034\n",
            "Epoch [600], val_loss: 7002.5640\n",
            "Epoch [620], val_loss: 7005.2642\n",
            "Epoch [640], val_loss: 7021.7017\n",
            "Epoch [660], val_loss: 7005.8022\n",
            "Epoch [680], val_loss: 6992.9375\n",
            "Epoch [700], val_loss: 6996.4790\n",
            "Epoch [720], val_loss: 6998.9478\n",
            "Epoch [740], val_loss: 6983.3071\n",
            "Epoch [760], val_loss: 6980.2739\n",
            "Epoch [780], val_loss: 7010.6987\n",
            "Epoch [800], val_loss: 6987.1665\n",
            "Epoch [820], val_loss: 6982.4253\n",
            "Epoch [840], val_loss: 6977.8989\n",
            "Epoch [860], val_loss: 6968.8237\n",
            "Epoch [880], val_loss: 6974.5884\n",
            "Epoch [900], val_loss: 6969.9082\n",
            "Epoch [920], val_loss: 6968.6289\n",
            "Epoch [940], val_loss: 6960.2866\n",
            "Epoch [960], val_loss: 6968.5864\n",
            "Epoch [980], val_loss: 6956.2852\n",
            "Epoch [1000], val_loss: 6962.6133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6prEpRR2aosf",
        "outputId": "6b113b91-fcbf-4ee6-d348-9be5e9517f06"
      },
      "source": [
        "epochs = 1000\n",
        "lr = 0.1\n",
        "history2 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6967.9136\n",
            "Epoch [40], val_loss: 6958.7695\n",
            "Epoch [60], val_loss: 6967.5210\n",
            "Epoch [80], val_loss: 6952.6152\n",
            "Epoch [100], val_loss: 6959.7070\n",
            "Epoch [120], val_loss: 6953.4819\n",
            "Epoch [140], val_loss: 6948.9609\n",
            "Epoch [160], val_loss: 6958.2603\n",
            "Epoch [180], val_loss: 6946.0015\n",
            "Epoch [200], val_loss: 6948.1992\n",
            "Epoch [220], val_loss: 6952.7778\n",
            "Epoch [240], val_loss: 6943.4478\n",
            "Epoch [260], val_loss: 6952.5190\n",
            "Epoch [280], val_loss: 6941.8950\n",
            "Epoch [300], val_loss: 6945.8647\n",
            "Epoch [320], val_loss: 6944.9712\n",
            "Epoch [340], val_loss: 6937.9868\n",
            "Epoch [360], val_loss: 6948.8354\n",
            "Epoch [380], val_loss: 6939.1030\n",
            "Epoch [400], val_loss: 6937.8613\n",
            "Epoch [420], val_loss: 6935.1392\n",
            "Epoch [440], val_loss: 6935.9922\n",
            "Epoch [460], val_loss: 6937.5215\n",
            "Epoch [480], val_loss: 6933.0415\n",
            "Epoch [500], val_loss: 6930.1548\n",
            "Epoch [520], val_loss: 6932.1660\n",
            "Epoch [540], val_loss: 6926.7632\n",
            "Epoch [560], val_loss: 6932.7515\n",
            "Epoch [580], val_loss: 6928.8276\n",
            "Epoch [600], val_loss: 6928.4751\n",
            "Epoch [620], val_loss: 6939.4863\n",
            "Epoch [640], val_loss: 6921.4771\n",
            "Epoch [660], val_loss: 6920.9751\n",
            "Epoch [680], val_loss: 6928.5659\n",
            "Epoch [700], val_loss: 6918.4829\n",
            "Epoch [720], val_loss: 6924.1641\n",
            "Epoch [740], val_loss: 6915.9727\n",
            "Epoch [760], val_loss: 6928.5122\n",
            "Epoch [780], val_loss: 6926.8867\n",
            "Epoch [800], val_loss: 6912.0625\n",
            "Epoch [820], val_loss: 6927.1641\n",
            "Epoch [840], val_loss: 6923.1870\n",
            "Epoch [860], val_loss: 6923.9204\n",
            "Epoch [880], val_loss: 6920.0874\n",
            "Epoch [900], val_loss: 6913.2515\n",
            "Epoch [920], val_loss: 6911.6055\n",
            "Epoch [940], val_loss: 6912.2515\n",
            "Epoch [960], val_loss: 6907.5728\n",
            "Epoch [980], val_loss: 6902.6069\n",
            "Epoch [1000], val_loss: 6905.4165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3Qx3QxHaosf",
        "outputId": "5b038cc0-353a-4bdf-be46-3b45b8ae6069"
      },
      "source": [
        "epochs = 1000\n",
        "lr = 0.6\n",
        "history3 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6892.8384\n",
            "Epoch [40], val_loss: 6890.4844\n",
            "Epoch [60], val_loss: 6884.3867\n",
            "Epoch [80], val_loss: 6892.7739\n",
            "Epoch [100], val_loss: 7073.9263\n",
            "Epoch [120], val_loss: 6864.5161\n",
            "Epoch [140], val_loss: 6864.6968\n",
            "Epoch [160], val_loss: 6851.6958\n",
            "Epoch [180], val_loss: 6846.0103\n",
            "Epoch [200], val_loss: 6850.2734\n",
            "Epoch [220], val_loss: 7046.2441\n",
            "Epoch [240], val_loss: 6953.2671\n",
            "Epoch [260], val_loss: 6907.4761\n",
            "Epoch [280], val_loss: 6850.9409\n",
            "Epoch [300], val_loss: 6996.0938\n",
            "Epoch [320], val_loss: 6843.9395\n",
            "Epoch [340], val_loss: 6874.0112\n",
            "Epoch [360], val_loss: 6801.4453\n",
            "Epoch [380], val_loss: 6821.5391\n",
            "Epoch [400], val_loss: 6859.4492\n",
            "Epoch [420], val_loss: 6775.2563\n",
            "Epoch [440], val_loss: 6803.1621\n",
            "Epoch [460], val_loss: 6845.9233\n",
            "Epoch [480], val_loss: 6758.1440\n",
            "Epoch [500], val_loss: 6848.4507\n",
            "Epoch [520], val_loss: 6942.0259\n",
            "Epoch [540], val_loss: 6877.0117\n",
            "Epoch [560], val_loss: 6757.2407\n",
            "Epoch [580], val_loss: 6731.1421\n",
            "Epoch [600], val_loss: 6722.2349\n",
            "Epoch [620], val_loss: 6740.8960\n",
            "Epoch [640], val_loss: 6722.3774\n",
            "Epoch [660], val_loss: 6713.6099\n",
            "Epoch [680], val_loss: 6705.8296\n",
            "Epoch [700], val_loss: 6694.2446\n",
            "Epoch [720], val_loss: 6717.4165\n",
            "Epoch [740], val_loss: 6927.8711\n",
            "Epoch [760], val_loss: 6714.6567\n",
            "Epoch [780], val_loss: 6990.7134\n",
            "Epoch [800], val_loss: 6672.8267\n",
            "Epoch [820], val_loss: 6662.8589\n",
            "Epoch [840], val_loss: 6697.9629\n",
            "Epoch [860], val_loss: 6650.1797\n",
            "Epoch [880], val_loss: 6657.2695\n",
            "Epoch [900], val_loss: 6694.1196\n",
            "Epoch [920], val_loss: 6667.6016\n",
            "Epoch [940], val_loss: 6680.0820\n",
            "Epoch [960], val_loss: 6669.5024\n",
            "Epoch [980], val_loss: 6617.1851\n",
            "Epoch [1000], val_loss: 6806.1699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbFkkMtRaosf",
        "outputId": "df81d737-4c5a-4e28-e0b9-3f35647e6c32"
      },
      "source": [
        "epochs = 1000\n",
        "lr = 0.2\n",
        "history4 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 6615.6133\n",
            "Epoch [40], val_loss: 6610.6758\n",
            "Epoch [60], val_loss: 6659.9380\n",
            "Epoch [80], val_loss: 6611.9800\n",
            "Epoch [100], val_loss: 6623.4116\n",
            "Epoch [120], val_loss: 6611.2886\n",
            "Epoch [140], val_loss: 6626.7637\n",
            "Epoch [160], val_loss: 6612.8237\n",
            "Epoch [180], val_loss: 6612.6055\n",
            "Epoch [200], val_loss: 6612.4595\n",
            "Epoch [220], val_loss: 6597.4082\n",
            "Epoch [240], val_loss: 6605.5195\n",
            "Epoch [260], val_loss: 6613.7124\n",
            "Epoch [280], val_loss: 6599.7070\n",
            "Epoch [300], val_loss: 6613.1157\n",
            "Epoch [320], val_loss: 6604.4224\n",
            "Epoch [340], val_loss: 6600.5767\n",
            "Epoch [360], val_loss: 6580.5532\n",
            "Epoch [380], val_loss: 6579.5039\n",
            "Epoch [400], val_loss: 6596.0757\n",
            "Epoch [420], val_loss: 6585.1758\n",
            "Epoch [440], val_loss: 6621.8823\n",
            "Epoch [460], val_loss: 6575.4204\n",
            "Epoch [480], val_loss: 6591.8110\n",
            "Epoch [500], val_loss: 6634.9453\n",
            "Epoch [520], val_loss: 6599.5776\n",
            "Epoch [540], val_loss: 6587.7754\n",
            "Epoch [560], val_loss: 6558.9995\n",
            "Epoch [580], val_loss: 6581.0337\n",
            "Epoch [600], val_loss: 6566.0874\n",
            "Epoch [620], val_loss: 6572.3013\n",
            "Epoch [640], val_loss: 6560.6040\n",
            "Epoch [660], val_loss: 6558.3110\n",
            "Epoch [680], val_loss: 6562.7407\n",
            "Epoch [700], val_loss: 6546.7305\n",
            "Epoch [720], val_loss: 6547.8423\n",
            "Epoch [740], val_loss: 6545.2827\n",
            "Epoch [760], val_loss: 6540.8335\n",
            "Epoch [780], val_loss: 6550.5820\n",
            "Epoch [800], val_loss: 6575.6133\n",
            "Epoch [820], val_loss: 6543.3813\n",
            "Epoch [840], val_loss: 6556.4980\n",
            "Epoch [860], val_loss: 6538.3032\n",
            "Epoch [880], val_loss: 6530.0776\n",
            "Epoch [900], val_loss: 6552.5093\n",
            "Epoch [920], val_loss: 6527.9595\n",
            "Epoch [940], val_loss: 6537.0278\n",
            "Epoch [960], val_loss: 6569.4883\n",
            "Epoch [980], val_loss: 6520.5845\n",
            "Epoch [1000], val_loss: 6518.6284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4RUSPxoaosf",
        "outputId": "a60ca8e0-5294-43ec-aa6f-c3f2b2c5c632"
      },
      "source": [
        "epochs = 50000\n",
        "lr = 7e-2\n",
        "history5 = fit(epochs, lr, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [20], val_loss: 3964.5769\n",
            "Epoch [40], val_loss: 3964.1238\n",
            "Epoch [60], val_loss: 3957.9539\n",
            "Epoch [80], val_loss: 3956.2927\n",
            "Epoch [100], val_loss: 3953.0156\n",
            "Epoch [120], val_loss: 3965.8542\n",
            "Epoch [140], val_loss: 3962.2546\n",
            "Epoch [160], val_loss: 3957.1047\n",
            "Epoch [180], val_loss: 3956.5320\n",
            "Epoch [200], val_loss: 3969.0959\n",
            "Epoch [220], val_loss: 3954.2288\n",
            "Epoch [240], val_loss: 3954.3164\n",
            "Epoch [260], val_loss: 3962.9160\n",
            "Epoch [280], val_loss: 3968.5039\n",
            "Epoch [300], val_loss: 3956.1797\n",
            "Epoch [320], val_loss: 3963.5930\n",
            "Epoch [340], val_loss: 3962.6162\n",
            "Epoch [360], val_loss: 3952.1648\n",
            "Epoch [380], val_loss: 3948.6331\n",
            "Epoch [400], val_loss: 3963.4512\n",
            "Epoch [420], val_loss: 3968.0847\n",
            "Epoch [440], val_loss: 3960.9006\n",
            "Epoch [460], val_loss: 3950.8367\n",
            "Epoch [480], val_loss: 3958.4836\n",
            "Epoch [500], val_loss: 3956.7852\n",
            "Epoch [520], val_loss: 3956.8464\n",
            "Epoch [540], val_loss: 3951.2317\n",
            "Epoch [560], val_loss: 3946.8740\n",
            "Epoch [580], val_loss: 3957.2500\n",
            "Epoch [600], val_loss: 3959.8516\n",
            "Epoch [620], val_loss: 3960.2795\n",
            "Epoch [640], val_loss: 3953.1765\n",
            "Epoch [660], val_loss: 3955.6829\n",
            "Epoch [680], val_loss: 3953.6267\n",
            "Epoch [700], val_loss: 3953.7844\n",
            "Epoch [720], val_loss: 3956.5818\n",
            "Epoch [740], val_loss: 3962.5789\n",
            "Epoch [760], val_loss: 3956.3914\n",
            "Epoch [780], val_loss: 3955.8203\n",
            "Epoch [800], val_loss: 3960.7786\n",
            "Epoch [820], val_loss: 3947.3274\n",
            "Epoch [840], val_loss: 3955.5085\n",
            "Epoch [860], val_loss: 3953.5752\n",
            "Epoch [880], val_loss: 3970.7610\n",
            "Epoch [900], val_loss: 3949.2031\n",
            "Epoch [920], val_loss: 3949.2122\n",
            "Epoch [940], val_loss: 3946.1582\n",
            "Epoch [960], val_loss: 3950.6335\n",
            "Epoch [980], val_loss: 3947.8855\n",
            "Epoch [1000], val_loss: 3957.4871\n",
            "Epoch [1020], val_loss: 3959.6172\n",
            "Epoch [1040], val_loss: 3956.1433\n",
            "Epoch [1060], val_loss: 3973.1621\n",
            "Epoch [1080], val_loss: 3963.2605\n",
            "Epoch [1100], val_loss: 3956.5447\n",
            "Epoch [1120], val_loss: 3945.9470\n",
            "Epoch [1140], val_loss: 3950.8330\n",
            "Epoch [1160], val_loss: 3951.2434\n",
            "Epoch [1180], val_loss: 3960.2957\n",
            "Epoch [1200], val_loss: 3954.0186\n",
            "Epoch [1220], val_loss: 3953.1726\n",
            "Epoch [1240], val_loss: 3963.7598\n",
            "Epoch [1260], val_loss: 3947.9167\n",
            "Epoch [1280], val_loss: 3948.8103\n",
            "Epoch [1300], val_loss: 3954.8220\n",
            "Epoch [1320], val_loss: 3962.9167\n",
            "Epoch [1340], val_loss: 3951.2815\n",
            "Epoch [1360], val_loss: 3950.9043\n",
            "Epoch [1380], val_loss: 3945.1982\n",
            "Epoch [1400], val_loss: 3948.3486\n",
            "Epoch [1420], val_loss: 3949.7402\n",
            "Epoch [1440], val_loss: 3952.2371\n",
            "Epoch [1460], val_loss: 3951.0081\n",
            "Epoch [1480], val_loss: 3943.8875\n",
            "Epoch [1500], val_loss: 3956.6863\n",
            "Epoch [1520], val_loss: 3949.6829\n",
            "Epoch [1540], val_loss: 3954.5652\n",
            "Epoch [1560], val_loss: 3955.6477\n",
            "Epoch [1580], val_loss: 3947.3464\n",
            "Epoch [1600], val_loss: 3946.0959\n",
            "Epoch [1620], val_loss: 3949.8047\n",
            "Epoch [1640], val_loss: 3953.5762\n",
            "Epoch [1660], val_loss: 3946.9744\n",
            "Epoch [1680], val_loss: 3951.1790\n",
            "Epoch [1700], val_loss: 3951.9001\n",
            "Epoch [1720], val_loss: 3948.0000\n",
            "Epoch [1740], val_loss: 3956.1780\n",
            "Epoch [1760], val_loss: 3954.1768\n",
            "Epoch [1780], val_loss: 3951.4500\n",
            "Epoch [1800], val_loss: 3944.2559\n",
            "Epoch [1820], val_loss: 3948.6223\n",
            "Epoch [1840], val_loss: 3958.0808\n",
            "Epoch [1860], val_loss: 3946.8542\n",
            "Epoch [1880], val_loss: 3944.7097\n",
            "Epoch [1900], val_loss: 3951.5813\n",
            "Epoch [1920], val_loss: 3951.1086\n",
            "Epoch [1940], val_loss: 3942.1885\n",
            "Epoch [1960], val_loss: 3951.0215\n",
            "Epoch [1980], val_loss: 3950.0559\n",
            "Epoch [2000], val_loss: 3957.0559\n",
            "Epoch [2020], val_loss: 3942.4551\n",
            "Epoch [2040], val_loss: 3943.7695\n",
            "Epoch [2060], val_loss: 3951.4250\n",
            "Epoch [2080], val_loss: 3942.7488\n",
            "Epoch [2100], val_loss: 3948.8008\n",
            "Epoch [2120], val_loss: 3939.6189\n",
            "Epoch [2140], val_loss: 3949.2871\n",
            "Epoch [2160], val_loss: 3942.0281\n",
            "Epoch [2180], val_loss: 3957.2188\n",
            "Epoch [2200], val_loss: 3947.5579\n",
            "Epoch [2220], val_loss: 3943.4492\n",
            "Epoch [2240], val_loss: 3952.3430\n",
            "Epoch [2260], val_loss: 3950.0007\n",
            "Epoch [2280], val_loss: 3947.2195\n",
            "Epoch [2300], val_loss: 3945.6414\n",
            "Epoch [2320], val_loss: 3947.2783\n",
            "Epoch [2340], val_loss: 3952.7883\n",
            "Epoch [2360], val_loss: 3943.1672\n",
            "Epoch [2380], val_loss: 3937.0481\n",
            "Epoch [2400], val_loss: 3943.0879\n",
            "Epoch [2420], val_loss: 3941.5586\n",
            "Epoch [2440], val_loss: 3938.2803\n",
            "Epoch [2460], val_loss: 3952.9297\n",
            "Epoch [2480], val_loss: 3944.6589\n",
            "Epoch [2500], val_loss: 3939.8289\n",
            "Epoch [2520], val_loss: 3941.6660\n",
            "Epoch [2540], val_loss: 3939.3186\n",
            "Epoch [2560], val_loss: 3955.5608\n",
            "Epoch [2580], val_loss: 3945.1299\n",
            "Epoch [2600], val_loss: 3948.5632\n",
            "Epoch [2620], val_loss: 3950.6077\n",
            "Epoch [2640], val_loss: 3955.5637\n",
            "Epoch [2660], val_loss: 3949.5400\n",
            "Epoch [2680], val_loss: 3945.4883\n",
            "Epoch [2700], val_loss: 3959.6101\n",
            "Epoch [2720], val_loss: 3965.6301\n",
            "Epoch [2740], val_loss: 3954.2656\n",
            "Epoch [2760], val_loss: 3947.1914\n",
            "Epoch [2780], val_loss: 3936.7976\n",
            "Epoch [2800], val_loss: 3939.2969\n",
            "Epoch [2820], val_loss: 3934.2952\n",
            "Epoch [2840], val_loss: 3945.4512\n",
            "Epoch [2860], val_loss: 3944.6699\n",
            "Epoch [2880], val_loss: 3942.2312\n",
            "Epoch [2900], val_loss: 3955.1614\n",
            "Epoch [2920], val_loss: 3946.4062\n",
            "Epoch [2940], val_loss: 3943.7576\n",
            "Epoch [2960], val_loss: 3952.0012\n",
            "Epoch [2980], val_loss: 3942.5774\n",
            "Epoch [3000], val_loss: 3955.1882\n",
            "Epoch [3020], val_loss: 3949.1765\n",
            "Epoch [3040], val_loss: 3941.8225\n",
            "Epoch [3060], val_loss: 3947.7722\n",
            "Epoch [3080], val_loss: 3937.4490\n",
            "Epoch [3100], val_loss: 3946.2803\n",
            "Epoch [3120], val_loss: 3939.5574\n",
            "Epoch [3140], val_loss: 3942.8972\n",
            "Epoch [3160], val_loss: 3940.7351\n",
            "Epoch [3180], val_loss: 3950.2761\n",
            "Epoch [3200], val_loss: 3942.3962\n",
            "Epoch [3220], val_loss: 3942.9597\n",
            "Epoch [3240], val_loss: 3935.3757\n",
            "Epoch [3260], val_loss: 3946.3574\n",
            "Epoch [3280], val_loss: 3933.3416\n",
            "Epoch [3300], val_loss: 3941.4734\n",
            "Epoch [3320], val_loss: 3951.2229\n",
            "Epoch [3340], val_loss: 3940.2786\n",
            "Epoch [3360], val_loss: 3943.7771\n",
            "Epoch [3380], val_loss: 3940.9043\n",
            "Epoch [3400], val_loss: 3968.2922\n",
            "Epoch [3420], val_loss: 3934.1934\n",
            "Epoch [3440], val_loss: 3946.1438\n",
            "Epoch [3460], val_loss: 3945.3699\n",
            "Epoch [3480], val_loss: 3949.1321\n",
            "Epoch [3500], val_loss: 3947.6816\n",
            "Epoch [3520], val_loss: 3936.4033\n",
            "Epoch [3540], val_loss: 3953.4851\n",
            "Epoch [3560], val_loss: 3944.0828\n",
            "Epoch [3580], val_loss: 3941.6133\n",
            "Epoch [3600], val_loss: 3948.4763\n",
            "Epoch [3620], val_loss: 3942.8049\n",
            "Epoch [3640], val_loss: 3932.0447\n",
            "Epoch [3660], val_loss: 3937.3730\n",
            "Epoch [3680], val_loss: 3949.0559\n",
            "Epoch [3700], val_loss: 3959.9207\n",
            "Epoch [3720], val_loss: 3942.6172\n",
            "Epoch [3740], val_loss: 3934.2363\n",
            "Epoch [3760], val_loss: 3952.7786\n",
            "Epoch [3780], val_loss: 3943.0911\n",
            "Epoch [3800], val_loss: 3939.5828\n",
            "Epoch [3820], val_loss: 3939.0791\n",
            "Epoch [3840], val_loss: 3936.8132\n",
            "Epoch [3860], val_loss: 3945.0725\n",
            "Epoch [3880], val_loss: 3939.1047\n",
            "Epoch [3900], val_loss: 3934.1387\n",
            "Epoch [3920], val_loss: 3941.4573\n",
            "Epoch [3940], val_loss: 3936.1565\n",
            "Epoch [3960], val_loss: 3939.3289\n",
            "Epoch [3980], val_loss: 3941.9500\n",
            "Epoch [4000], val_loss: 3950.8274\n",
            "Epoch [4020], val_loss: 3938.4543\n",
            "Epoch [4040], val_loss: 3939.8738\n",
            "Epoch [4060], val_loss: 3953.0388\n",
            "Epoch [4080], val_loss: 3938.9570\n",
            "Epoch [4100], val_loss: 3939.9619\n",
            "Epoch [4120], val_loss: 3935.0664\n",
            "Epoch [4140], val_loss: 3943.4597\n",
            "Epoch [4160], val_loss: 3936.4460\n",
            "Epoch [4180], val_loss: 3939.5559\n",
            "Epoch [4200], val_loss: 3935.2380\n",
            "Epoch [4220], val_loss: 3933.6445\n",
            "Epoch [4240], val_loss: 3936.2317\n",
            "Epoch [4260], val_loss: 3948.1907\n",
            "Epoch [4280], val_loss: 3950.1257\n",
            "Epoch [4300], val_loss: 3940.5984\n",
            "Epoch [4320], val_loss: 3932.6204\n",
            "Epoch [4340], val_loss: 3932.8406\n",
            "Epoch [4360], val_loss: 3933.0027\n",
            "Epoch [4380], val_loss: 3935.7410\n",
            "Epoch [4400], val_loss: 3939.3894\n",
            "Epoch [4420], val_loss: 3931.0906\n",
            "Epoch [4440], val_loss: 3936.9714\n",
            "Epoch [4460], val_loss: 3928.8235\n",
            "Epoch [4480], val_loss: 3941.8562\n",
            "Epoch [4500], val_loss: 3939.9199\n",
            "Epoch [4520], val_loss: 3935.9207\n",
            "Epoch [4540], val_loss: 3937.6523\n",
            "Epoch [4560], val_loss: 3938.3652\n",
            "Epoch [4580], val_loss: 3936.3230\n",
            "Epoch [4600], val_loss: 3925.8936\n",
            "Epoch [4620], val_loss: 3935.3186\n",
            "Epoch [4640], val_loss: 3932.8528\n",
            "Epoch [4660], val_loss: 3939.3516\n",
            "Epoch [4680], val_loss: 3937.5618\n",
            "Epoch [4700], val_loss: 3944.8743\n",
            "Epoch [4720], val_loss: 3941.3088\n",
            "Epoch [4740], val_loss: 3931.6418\n",
            "Epoch [4760], val_loss: 3935.5762\n",
            "Epoch [4780], val_loss: 3943.1191\n",
            "Epoch [4800], val_loss: 3938.5234\n",
            "Epoch [4820], val_loss: 3938.1729\n",
            "Epoch [4840], val_loss: 3930.8152\n",
            "Epoch [4860], val_loss: 3930.7610\n",
            "Epoch [4880], val_loss: 3933.5654\n",
            "Epoch [4900], val_loss: 3932.6750\n",
            "Epoch [4920], val_loss: 3931.6785\n",
            "Epoch [4940], val_loss: 3938.2839\n",
            "Epoch [4960], val_loss: 3940.3977\n",
            "Epoch [4980], val_loss: 3944.1260\n",
            "Epoch [5000], val_loss: 3938.5989\n",
            "Epoch [5020], val_loss: 3934.3308\n",
            "Epoch [5040], val_loss: 3940.5762\n",
            "Epoch [5060], val_loss: 3933.1926\n",
            "Epoch [5080], val_loss: 3926.0723\n",
            "Epoch [5100], val_loss: 3931.2375\n",
            "Epoch [5120], val_loss: 3930.1250\n",
            "Epoch [5140], val_loss: 3938.8391\n",
            "Epoch [5160], val_loss: 3933.3835\n",
            "Epoch [5180], val_loss: 3941.4485\n",
            "Epoch [5200], val_loss: 3923.7305\n",
            "Epoch [5220], val_loss: 3932.5105\n",
            "Epoch [5240], val_loss: 3932.4736\n",
            "Epoch [5260], val_loss: 3932.0127\n",
            "Epoch [5280], val_loss: 3935.8223\n",
            "Epoch [5300], val_loss: 3938.8186\n",
            "Epoch [5320], val_loss: 3925.8672\n",
            "Epoch [5340], val_loss: 3930.4675\n",
            "Epoch [5360], val_loss: 3936.6125\n",
            "Epoch [5380], val_loss: 3939.3933\n",
            "Epoch [5400], val_loss: 3933.5286\n",
            "Epoch [5420], val_loss: 3932.6865\n",
            "Epoch [5440], val_loss: 3937.3289\n",
            "Epoch [5460], val_loss: 3934.8977\n",
            "Epoch [5480], val_loss: 3948.5078\n",
            "Epoch [5500], val_loss: 3937.3210\n",
            "Epoch [5520], val_loss: 3934.8721\n",
            "Epoch [5540], val_loss: 3933.0007\n",
            "Epoch [5560], val_loss: 3926.4563\n",
            "Epoch [5580], val_loss: 3933.9446\n",
            "Epoch [5600], val_loss: 3931.4026\n",
            "Epoch [5620], val_loss: 3926.3743\n",
            "Epoch [5640], val_loss: 3926.5078\n",
            "Epoch [5660], val_loss: 3927.2988\n",
            "Epoch [5680], val_loss: 3932.4167\n",
            "Epoch [5700], val_loss: 3928.2434\n",
            "Epoch [5720], val_loss: 3935.9426\n",
            "Epoch [5740], val_loss: 3936.7266\n",
            "Epoch [5760], val_loss: 3937.1204\n",
            "Epoch [5780], val_loss: 3925.3594\n",
            "Epoch [5800], val_loss: 3931.0789\n",
            "Epoch [5820], val_loss: 3931.6692\n",
            "Epoch [5840], val_loss: 3924.8699\n",
            "Epoch [5860], val_loss: 3938.7312\n",
            "Epoch [5880], val_loss: 3929.6746\n",
            "Epoch [5900], val_loss: 3935.1477\n",
            "Epoch [5920], val_loss: 3929.5410\n",
            "Epoch [5940], val_loss: 3926.0735\n",
            "Epoch [5960], val_loss: 3932.5779\n",
            "Epoch [5980], val_loss: 3937.1611\n",
            "Epoch [6000], val_loss: 3926.2292\n",
            "Epoch [6020], val_loss: 3928.2546\n",
            "Epoch [6040], val_loss: 3928.4121\n",
            "Epoch [6060], val_loss: 3925.9680\n",
            "Epoch [6080], val_loss: 3928.9941\n",
            "Epoch [6100], val_loss: 3924.0430\n",
            "Epoch [6120], val_loss: 3936.7742\n",
            "Epoch [6140], val_loss: 3937.3818\n",
            "Epoch [6160], val_loss: 3923.4980\n",
            "Epoch [6180], val_loss: 3930.9719\n",
            "Epoch [6200], val_loss: 3931.4070\n",
            "Epoch [6220], val_loss: 3934.9309\n",
            "Epoch [6240], val_loss: 3924.3152\n",
            "Epoch [6260], val_loss: 3939.6277\n",
            "Epoch [6280], val_loss: 3935.1331\n",
            "Epoch [6300], val_loss: 3922.4641\n",
            "Epoch [6320], val_loss: 3927.0300\n",
            "Epoch [6340], val_loss: 3925.8018\n",
            "Epoch [6360], val_loss: 3919.5430\n",
            "Epoch [6380], val_loss: 3939.6462\n",
            "Epoch [6400], val_loss: 3941.6238\n",
            "Epoch [6420], val_loss: 3924.9241\n",
            "Epoch [6440], val_loss: 3933.4023\n",
            "Epoch [6460], val_loss: 3934.4255\n",
            "Epoch [6480], val_loss: 3925.0281\n",
            "Epoch [6500], val_loss: 3925.5488\n",
            "Epoch [6520], val_loss: 3923.6963\n",
            "Epoch [6540], val_loss: 3927.4373\n",
            "Epoch [6560], val_loss: 3930.1970\n",
            "Epoch [6580], val_loss: 3920.8411\n",
            "Epoch [6600], val_loss: 3938.6270\n",
            "Epoch [6620], val_loss: 3924.2141\n",
            "Epoch [6640], val_loss: 3932.8594\n",
            "Epoch [6660], val_loss: 3926.3977\n",
            "Epoch [6680], val_loss: 3928.2917\n",
            "Epoch [6700], val_loss: 3928.5762\n",
            "Epoch [6720], val_loss: 3926.7205\n",
            "Epoch [6740], val_loss: 3922.7637\n",
            "Epoch [6760], val_loss: 3932.3840\n",
            "Epoch [6780], val_loss: 3933.4983\n",
            "Epoch [6800], val_loss: 3931.2148\n",
            "Epoch [6820], val_loss: 3939.4856\n",
            "Epoch [6840], val_loss: 3919.3027\n",
            "Epoch [6860], val_loss: 3920.8948\n",
            "Epoch [6880], val_loss: 3938.7478\n",
            "Epoch [6900], val_loss: 3932.1204\n",
            "Epoch [6920], val_loss: 3925.2917\n",
            "Epoch [6940], val_loss: 3928.3711\n",
            "Epoch [6960], val_loss: 3925.4329\n",
            "Epoch [6980], val_loss: 3923.3093\n",
            "Epoch [7000], val_loss: 3923.0527\n",
            "Epoch [7020], val_loss: 3931.7253\n",
            "Epoch [7040], val_loss: 3922.4084\n",
            "Epoch [7060], val_loss: 3919.5208\n",
            "Epoch [7080], val_loss: 3930.7468\n",
            "Epoch [7100], val_loss: 3926.9629\n",
            "Epoch [7120], val_loss: 3925.4817\n",
            "Epoch [7140], val_loss: 3931.0764\n",
            "Epoch [7160], val_loss: 3918.6418\n",
            "Epoch [7180], val_loss: 3921.3018\n",
            "Epoch [7200], val_loss: 3922.8298\n",
            "Epoch [7220], val_loss: 3931.3770\n",
            "Epoch [7240], val_loss: 3928.4124\n",
            "Epoch [7260], val_loss: 3919.3418\n",
            "Epoch [7280], val_loss: 3924.0437\n",
            "Epoch [7300], val_loss: 3927.5129\n",
            "Epoch [7320], val_loss: 3918.9915\n",
            "Epoch [7340], val_loss: 3925.4646\n",
            "Epoch [7360], val_loss: 3930.0742\n",
            "Epoch [7380], val_loss: 3918.1887\n",
            "Epoch [7400], val_loss: 3934.9075\n",
            "Epoch [7420], val_loss: 3927.5430\n",
            "Epoch [7440], val_loss: 3931.2715\n",
            "Epoch [7460], val_loss: 3919.3157\n",
            "Epoch [7480], val_loss: 3922.2559\n",
            "Epoch [7500], val_loss: 3933.3372\n",
            "Epoch [7520], val_loss: 3923.4607\n",
            "Epoch [7540], val_loss: 3928.7803\n",
            "Epoch [7560], val_loss: 3918.2253\n",
            "Epoch [7580], val_loss: 3930.6975\n",
            "Epoch [7600], val_loss: 3917.5117\n",
            "Epoch [7620], val_loss: 3918.8506\n",
            "Epoch [7640], val_loss: 3922.8567\n",
            "Epoch [7660], val_loss: 3916.2871\n",
            "Epoch [7680], val_loss: 3926.4961\n",
            "Epoch [7700], val_loss: 3921.9570\n",
            "Epoch [7720], val_loss: 3916.8672\n",
            "Epoch [7740], val_loss: 3913.3972\n",
            "Epoch [7760], val_loss: 3921.1113\n",
            "Epoch [7780], val_loss: 3934.1230\n",
            "Epoch [7800], val_loss: 3920.5334\n",
            "Epoch [7820], val_loss: 3930.2190\n",
            "Epoch [7840], val_loss: 3924.3105\n",
            "Epoch [7860], val_loss: 3919.9954\n",
            "Epoch [7880], val_loss: 3918.5459\n",
            "Epoch [7900], val_loss: 3932.2734\n",
            "Epoch [7920], val_loss: 3925.6875\n",
            "Epoch [7940], val_loss: 3920.0813\n",
            "Epoch [7960], val_loss: 3924.9785\n",
            "Epoch [7980], val_loss: 3921.2695\n",
            "Epoch [8000], val_loss: 3929.0481\n",
            "Epoch [8020], val_loss: 3924.6760\n",
            "Epoch [8040], val_loss: 3919.5891\n",
            "Epoch [8060], val_loss: 3925.6946\n",
            "Epoch [8080], val_loss: 3927.3223\n",
            "Epoch [8100], val_loss: 3923.6726\n",
            "Epoch [8120], val_loss: 3913.9641\n",
            "Epoch [8140], val_loss: 3917.7097\n",
            "Epoch [8160], val_loss: 3920.1643\n",
            "Epoch [8180], val_loss: 3920.7253\n",
            "Epoch [8200], val_loss: 3926.9883\n",
            "Epoch [8220], val_loss: 3926.4746\n",
            "Epoch [8240], val_loss: 3914.0598\n",
            "Epoch [8260], val_loss: 3932.9114\n",
            "Epoch [8280], val_loss: 3916.0566\n",
            "Epoch [8300], val_loss: 3921.8411\n",
            "Epoch [8320], val_loss: 3922.0403\n",
            "Epoch [8340], val_loss: 3914.3320\n",
            "Epoch [8360], val_loss: 3924.8582\n",
            "Epoch [8380], val_loss: 3916.1809\n",
            "Epoch [8400], val_loss: 3926.3054\n",
            "Epoch [8420], val_loss: 3922.1902\n",
            "Epoch [8440], val_loss: 3920.8118\n",
            "Epoch [8460], val_loss: 3919.8762\n",
            "Epoch [8480], val_loss: 3917.0850\n",
            "Epoch [8500], val_loss: 3924.8655\n",
            "Epoch [8520], val_loss: 3914.4648\n",
            "Epoch [8540], val_loss: 3921.1133\n",
            "Epoch [8560], val_loss: 3915.7676\n",
            "Epoch [8580], val_loss: 3913.7175\n",
            "Epoch [8600], val_loss: 3924.4062\n",
            "Epoch [8620], val_loss: 3919.3259\n",
            "Epoch [8640], val_loss: 3912.9807\n",
            "Epoch [8660], val_loss: 3914.7898\n",
            "Epoch [8680], val_loss: 3916.8020\n",
            "Epoch [8700], val_loss: 3918.4529\n",
            "Epoch [8720], val_loss: 3916.0488\n",
            "Epoch [8740], val_loss: 3916.7500\n",
            "Epoch [8760], val_loss: 3921.1003\n",
            "Epoch [8780], val_loss: 3910.2556\n",
            "Epoch [8800], val_loss: 3918.1768\n",
            "Epoch [8820], val_loss: 3930.6448\n",
            "Epoch [8840], val_loss: 3914.6016\n",
            "Epoch [8860], val_loss: 3920.1592\n",
            "Epoch [8880], val_loss: 3920.6455\n",
            "Epoch [8900], val_loss: 3916.5442\n",
            "Epoch [8920], val_loss: 3915.4326\n",
            "Epoch [8940], val_loss: 3919.6484\n",
            "Epoch [8960], val_loss: 3916.2136\n",
            "Epoch [8980], val_loss: 3926.0989\n",
            "Epoch [9000], val_loss: 3914.2595\n",
            "Epoch [9020], val_loss: 3913.7546\n",
            "Epoch [9040], val_loss: 3928.8582\n",
            "Epoch [9060], val_loss: 3913.1135\n",
            "Epoch [9080], val_loss: 3917.6360\n",
            "Epoch [9100], val_loss: 3914.2351\n",
            "Epoch [9120], val_loss: 3911.3445\n",
            "Epoch [9140], val_loss: 3913.7449\n",
            "Epoch [9160], val_loss: 3934.3320\n",
            "Epoch [9180], val_loss: 3914.7156\n",
            "Epoch [9200], val_loss: 3922.2234\n",
            "Epoch [9220], val_loss: 3913.7429\n",
            "Epoch [9240], val_loss: 3911.8533\n",
            "Epoch [9260], val_loss: 3924.0559\n",
            "Epoch [9280], val_loss: 3912.4705\n",
            "Epoch [9300], val_loss: 3917.6677\n",
            "Epoch [9320], val_loss: 3912.8086\n",
            "Epoch [9340], val_loss: 3910.7722\n",
            "Epoch [9360], val_loss: 3910.8496\n",
            "Epoch [9380], val_loss: 3912.3171\n",
            "Epoch [9400], val_loss: 3915.0645\n",
            "Epoch [9420], val_loss: 3931.4980\n",
            "Epoch [9440], val_loss: 3912.1609\n",
            "Epoch [9460], val_loss: 3916.4395\n",
            "Epoch [9480], val_loss: 3913.5413\n",
            "Epoch [9500], val_loss: 3913.6125\n",
            "Epoch [9520], val_loss: 3915.7979\n",
            "Epoch [9540], val_loss: 3915.7520\n",
            "Epoch [9560], val_loss: 3910.1584\n",
            "Epoch [9580], val_loss: 3934.3652\n",
            "Epoch [9600], val_loss: 3913.9465\n",
            "Epoch [9620], val_loss: 3920.7737\n",
            "Epoch [9640], val_loss: 3920.4805\n",
            "Epoch [9660], val_loss: 3915.9744\n",
            "Epoch [9680], val_loss: 3911.2812\n",
            "Epoch [9700], val_loss: 3915.1836\n",
            "Epoch [9720], val_loss: 3911.5730\n",
            "Epoch [9740], val_loss: 3909.7600\n",
            "Epoch [9760], val_loss: 3908.1462\n",
            "Epoch [9780], val_loss: 3922.0457\n",
            "Epoch [9800], val_loss: 3911.2029\n",
            "Epoch [9820], val_loss: 3912.1914\n",
            "Epoch [9840], val_loss: 3912.6875\n",
            "Epoch [9860], val_loss: 3917.1748\n",
            "Epoch [9880], val_loss: 3914.2449\n",
            "Epoch [9900], val_loss: 3919.0305\n",
            "Epoch [9920], val_loss: 3931.4792\n",
            "Epoch [9940], val_loss: 3919.9602\n",
            "Epoch [9960], val_loss: 3914.2561\n",
            "Epoch [9980], val_loss: 3919.9656\n",
            "Epoch [10000], val_loss: 3907.6016\n",
            "Epoch [10020], val_loss: 3911.5029\n",
            "Epoch [10040], val_loss: 3909.1628\n",
            "Epoch [10060], val_loss: 3924.5173\n",
            "Epoch [10080], val_loss: 3917.9551\n",
            "Epoch [10100], val_loss: 3910.7637\n",
            "Epoch [10120], val_loss: 3914.1160\n",
            "Epoch [10140], val_loss: 3911.1780\n",
            "Epoch [10160], val_loss: 3913.8450\n",
            "Epoch [10180], val_loss: 3909.6990\n",
            "Epoch [10200], val_loss: 3920.2288\n",
            "Epoch [10220], val_loss: 3914.4622\n",
            "Epoch [10240], val_loss: 3913.6492\n",
            "Epoch [10260], val_loss: 3913.2646\n",
            "Epoch [10280], val_loss: 3907.9775\n",
            "Epoch [10300], val_loss: 3912.9377\n",
            "Epoch [10320], val_loss: 3912.6179\n",
            "Epoch [10340], val_loss: 3916.1067\n",
            "Epoch [10360], val_loss: 3911.6729\n",
            "Epoch [10380], val_loss: 3921.2441\n",
            "Epoch [10400], val_loss: 3907.5227\n",
            "Epoch [10420], val_loss: 3914.4590\n",
            "Epoch [10440], val_loss: 3913.3533\n",
            "Epoch [10460], val_loss: 3909.3835\n",
            "Epoch [10480], val_loss: 3919.7039\n",
            "Epoch [10500], val_loss: 3911.2051\n",
            "Epoch [10520], val_loss: 3918.4509\n",
            "Epoch [10540], val_loss: 3907.3054\n",
            "Epoch [10560], val_loss: 3917.9539\n",
            "Epoch [10580], val_loss: 3930.1526\n",
            "Epoch [10600], val_loss: 3920.1086\n",
            "Epoch [10620], val_loss: 3920.7961\n",
            "Epoch [10640], val_loss: 3906.5657\n",
            "Epoch [10660], val_loss: 3915.3718\n",
            "Epoch [10680], val_loss: 3912.2292\n",
            "Epoch [10700], val_loss: 3912.2715\n",
            "Epoch [10720], val_loss: 3914.6191\n",
            "Epoch [10740], val_loss: 3910.5520\n",
            "Epoch [10760], val_loss: 3913.3601\n",
            "Epoch [10780], val_loss: 3905.9426\n",
            "Epoch [10800], val_loss: 3913.3242\n",
            "Epoch [10820], val_loss: 3915.6140\n",
            "Epoch [10840], val_loss: 3906.2859\n",
            "Epoch [10860], val_loss: 3910.5339\n",
            "Epoch [10880], val_loss: 3918.0183\n",
            "Epoch [10900], val_loss: 3915.2527\n",
            "Epoch [10920], val_loss: 3906.7402\n",
            "Epoch [10940], val_loss: 3916.3875\n",
            "Epoch [10960], val_loss: 3918.0371\n",
            "Epoch [10980], val_loss: 3909.1414\n",
            "Epoch [11000], val_loss: 3904.5527\n",
            "Epoch [11020], val_loss: 3909.6614\n",
            "Epoch [11040], val_loss: 3908.1868\n",
            "Epoch [11060], val_loss: 3907.5830\n",
            "Epoch [11080], val_loss: 3912.8938\n",
            "Epoch [11100], val_loss: 3907.3652\n",
            "Epoch [11120], val_loss: 3904.0935\n",
            "Epoch [11140], val_loss: 3910.8779\n",
            "Epoch [11160], val_loss: 3913.8906\n",
            "Epoch [11180], val_loss: 3909.9758\n",
            "Epoch [11200], val_loss: 3911.7246\n",
            "Epoch [11220], val_loss: 3909.0671\n",
            "Epoch [11240], val_loss: 3904.3528\n",
            "Epoch [11260], val_loss: 3918.4219\n",
            "Epoch [11280], val_loss: 3906.1731\n",
            "Epoch [11300], val_loss: 3913.2605\n",
            "Epoch [11320], val_loss: 3909.2637\n",
            "Epoch [11340], val_loss: 3920.2078\n",
            "Epoch [11360], val_loss: 3914.5793\n",
            "Epoch [11380], val_loss: 3910.8821\n",
            "Epoch [11400], val_loss: 3904.5430\n",
            "Epoch [11420], val_loss: 3907.9915\n",
            "Epoch [11440], val_loss: 3904.6201\n",
            "Epoch [11460], val_loss: 3920.5518\n",
            "Epoch [11480], val_loss: 3921.7383\n",
            "Epoch [11500], val_loss: 3907.7969\n",
            "Epoch [11520], val_loss: 3905.1423\n",
            "Epoch [11540], val_loss: 3906.9521\n",
            "Epoch [11560], val_loss: 3912.6965\n",
            "Epoch [11580], val_loss: 3904.8660\n",
            "Epoch [11600], val_loss: 3908.3840\n",
            "Epoch [11620], val_loss: 3911.3425\n",
            "Epoch [11640], val_loss: 3904.1094\n",
            "Epoch [11660], val_loss: 3915.3850\n",
            "Epoch [11680], val_loss: 3911.0925\n",
            "Epoch [11700], val_loss: 3909.6204\n",
            "Epoch [11720], val_loss: 3904.4890\n",
            "Epoch [11740], val_loss: 3903.7864\n",
            "Epoch [11760], val_loss: 3909.1914\n",
            "Epoch [11780], val_loss: 3911.1726\n",
            "Epoch [11800], val_loss: 3911.0579\n",
            "Epoch [11820], val_loss: 3913.0266\n",
            "Epoch [11840], val_loss: 3903.8496\n",
            "Epoch [11860], val_loss: 3905.7986\n",
            "Epoch [11880], val_loss: 3921.5676\n",
            "Epoch [11900], val_loss: 3915.5652\n",
            "Epoch [11920], val_loss: 3905.0127\n",
            "Epoch [11940], val_loss: 3918.5803\n",
            "Epoch [11960], val_loss: 3915.1609\n",
            "Epoch [11980], val_loss: 3904.3838\n",
            "Epoch [12000], val_loss: 3909.9541\n",
            "Epoch [12020], val_loss: 3902.8113\n",
            "Epoch [12040], val_loss: 3904.0090\n",
            "Epoch [12060], val_loss: 3906.3708\n",
            "Epoch [12080], val_loss: 3909.7305\n",
            "Epoch [12100], val_loss: 3907.4219\n",
            "Epoch [12120], val_loss: 3927.1453\n",
            "Epoch [12140], val_loss: 3908.7188\n",
            "Epoch [12160], val_loss: 3905.0886\n",
            "Epoch [12180], val_loss: 3905.9988\n",
            "Epoch [12200], val_loss: 3903.4050\n",
            "Epoch [12220], val_loss: 3909.0833\n",
            "Epoch [12240], val_loss: 3905.9531\n",
            "Epoch [12260], val_loss: 3903.8269\n",
            "Epoch [12280], val_loss: 3907.3782\n",
            "Epoch [12300], val_loss: 3904.5823\n",
            "Epoch [12320], val_loss: 3917.2151\n",
            "Epoch [12340], val_loss: 3913.6599\n",
            "Epoch [12360], val_loss: 3901.5164\n",
            "Epoch [12380], val_loss: 3916.8269\n",
            "Epoch [12400], val_loss: 3905.8772\n",
            "Epoch [12420], val_loss: 3909.0325\n",
            "Epoch [12440], val_loss: 3907.4500\n",
            "Epoch [12460], val_loss: 3914.1270\n",
            "Epoch [12480], val_loss: 3906.8586\n",
            "Epoch [12500], val_loss: 3910.1199\n",
            "Epoch [12520], val_loss: 3906.2646\n",
            "Epoch [12540], val_loss: 3904.1980\n",
            "Epoch [12560], val_loss: 3918.0618\n",
            "Epoch [12580], val_loss: 3908.0374\n",
            "Epoch [12600], val_loss: 3907.8948\n",
            "Epoch [12620], val_loss: 3910.1985\n",
            "Epoch [12640], val_loss: 3900.6504\n",
            "Epoch [12660], val_loss: 3907.9062\n",
            "Epoch [12680], val_loss: 3901.2454\n",
            "Epoch [12700], val_loss: 3899.3865\n",
            "Epoch [12720], val_loss: 3906.0967\n",
            "Epoch [12740], val_loss: 3901.9910\n",
            "Epoch [12760], val_loss: 3905.9375\n",
            "Epoch [12780], val_loss: 3900.8428\n",
            "Epoch [12800], val_loss: 3902.9719\n",
            "Epoch [12820], val_loss: 3901.2546\n",
            "Epoch [12840], val_loss: 3908.7996\n",
            "Epoch [12860], val_loss: 3901.0286\n",
            "Epoch [12880], val_loss: 3904.3015\n",
            "Epoch [12900], val_loss: 3898.3523\n",
            "Epoch [12920], val_loss: 3905.9766\n",
            "Epoch [12940], val_loss: 3910.5779\n",
            "Epoch [12960], val_loss: 3913.7810\n",
            "Epoch [12980], val_loss: 3911.1365\n",
            "Epoch [13000], val_loss: 3909.7793\n",
            "Epoch [13020], val_loss: 3898.7031\n",
            "Epoch [13040], val_loss: 3901.4824\n",
            "Epoch [13060], val_loss: 3907.6140\n",
            "Epoch [13080], val_loss: 3907.6738\n",
            "Epoch [13100], val_loss: 3922.2004\n",
            "Epoch [13120], val_loss: 3904.0293\n",
            "Epoch [13140], val_loss: 3909.3967\n",
            "Epoch [13160], val_loss: 3901.2815\n",
            "Epoch [13180], val_loss: 3896.9739\n",
            "Epoch [13200], val_loss: 3900.5793\n",
            "Epoch [13220], val_loss: 3907.4851\n",
            "Epoch [13240], val_loss: 3903.5383\n",
            "Epoch [13260], val_loss: 3907.4580\n",
            "Epoch [13280], val_loss: 3902.2246\n",
            "Epoch [13300], val_loss: 3906.9465\n",
            "Epoch [13320], val_loss: 3924.8469\n",
            "Epoch [13340], val_loss: 3902.1370\n",
            "Epoch [13360], val_loss: 3906.0459\n",
            "Epoch [13380], val_loss: 3898.0422\n",
            "Epoch [13400], val_loss: 3898.2244\n",
            "Epoch [13420], val_loss: 3897.9219\n",
            "Epoch [13440], val_loss: 3915.1331\n",
            "Epoch [13460], val_loss: 3907.6609\n",
            "Epoch [13480], val_loss: 3900.1785\n",
            "Epoch [13500], val_loss: 3910.0793\n",
            "Epoch [13520], val_loss: 3906.1218\n",
            "Epoch [13540], val_loss: 3899.6707\n",
            "Epoch [13560], val_loss: 3900.8181\n",
            "Epoch [13580], val_loss: 3903.3125\n",
            "Epoch [13600], val_loss: 3910.5222\n",
            "Epoch [13620], val_loss: 3900.7656\n",
            "Epoch [13640], val_loss: 3918.8818\n",
            "Epoch [13660], val_loss: 3895.3425\n",
            "Epoch [13680], val_loss: 3908.6907\n",
            "Epoch [13700], val_loss: 3908.4587\n",
            "Epoch [13720], val_loss: 3909.0996\n",
            "Epoch [13740], val_loss: 3902.1047\n",
            "Epoch [13760], val_loss: 3898.3743\n",
            "Epoch [13780], val_loss: 3898.6992\n",
            "Epoch [13800], val_loss: 3901.1482\n",
            "Epoch [13820], val_loss: 3899.3367\n",
            "Epoch [13840], val_loss: 3912.6816\n",
            "Epoch [13860], val_loss: 3900.5439\n",
            "Epoch [13880], val_loss: 3899.2549\n",
            "Epoch [13900], val_loss: 3908.8904\n",
            "Epoch [13920], val_loss: 3913.2937\n",
            "Epoch [13940], val_loss: 3910.8118\n",
            "Epoch [13960], val_loss: 3900.8057\n",
            "Epoch [13980], val_loss: 3906.9980\n",
            "Epoch [14000], val_loss: 3910.8496\n",
            "Epoch [14020], val_loss: 3915.4746\n",
            "Epoch [14040], val_loss: 3904.4766\n",
            "Epoch [14060], val_loss: 3913.5059\n",
            "Epoch [14080], val_loss: 3907.5977\n",
            "Epoch [14100], val_loss: 3902.7686\n",
            "Epoch [14120], val_loss: 3912.5491\n",
            "Epoch [14140], val_loss: 3902.0742\n",
            "Epoch [14160], val_loss: 3902.9290\n",
            "Epoch [14180], val_loss: 3907.0579\n",
            "Epoch [14200], val_loss: 3912.6560\n",
            "Epoch [14220], val_loss: 3906.4426\n",
            "Epoch [14240], val_loss: 3903.3867\n",
            "Epoch [14260], val_loss: 3900.6633\n",
            "Epoch [14280], val_loss: 3902.2361\n",
            "Epoch [14300], val_loss: 3897.8020\n",
            "Epoch [14320], val_loss: 3905.2334\n",
            "Epoch [14340], val_loss: 3908.4758\n",
            "Epoch [14360], val_loss: 3913.0693\n",
            "Epoch [14380], val_loss: 3901.7764\n",
            "Epoch [14400], val_loss: 3898.8367\n",
            "Epoch [14420], val_loss: 3909.6277\n",
            "Epoch [14440], val_loss: 3900.7185\n",
            "Epoch [14460], val_loss: 3902.9070\n",
            "Epoch [14480], val_loss: 3896.1406\n",
            "Epoch [14500], val_loss: 3912.7292\n",
            "Epoch [14520], val_loss: 3903.1257\n",
            "Epoch [14540], val_loss: 3901.2922\n",
            "Epoch [14560], val_loss: 3903.8926\n",
            "Epoch [14580], val_loss: 3907.5461\n",
            "Epoch [14600], val_loss: 3907.3271\n",
            "Epoch [14620], val_loss: 3901.1672\n",
            "Epoch [14640], val_loss: 3912.5156\n",
            "Epoch [14660], val_loss: 3906.5281\n",
            "Epoch [14680], val_loss: 3904.8887\n",
            "Epoch [14700], val_loss: 3908.9607\n",
            "Epoch [14720], val_loss: 3904.6521\n",
            "Epoch [14740], val_loss: 3895.9980\n",
            "Epoch [14760], val_loss: 3902.7605\n",
            "Epoch [14780], val_loss: 3910.0039\n",
            "Epoch [14800], val_loss: 3906.7227\n",
            "Epoch [14820], val_loss: 3900.2207\n",
            "Epoch [14840], val_loss: 3900.1204\n",
            "Epoch [14860], val_loss: 3893.0676\n",
            "Epoch [14880], val_loss: 3901.4590\n",
            "Epoch [14900], val_loss: 3909.0359\n",
            "Epoch [14920], val_loss: 3901.8262\n",
            "Epoch [14940], val_loss: 3905.2253\n",
            "Epoch [14960], val_loss: 3897.2285\n",
            "Epoch [14980], val_loss: 3900.3069\n",
            "Epoch [15000], val_loss: 3908.2175\n",
            "Epoch [15020], val_loss: 3902.3958\n",
            "Epoch [15040], val_loss: 3897.9924\n",
            "Epoch [15060], val_loss: 3904.9539\n",
            "Epoch [15080], val_loss: 3895.5544\n",
            "Epoch [15100], val_loss: 3893.4756\n",
            "Epoch [15120], val_loss: 3901.6750\n",
            "Epoch [15140], val_loss: 3894.9700\n",
            "Epoch [15160], val_loss: 3901.4675\n",
            "Epoch [15180], val_loss: 3897.5632\n",
            "Epoch [15200], val_loss: 3896.5754\n",
            "Epoch [15220], val_loss: 3896.0830\n",
            "Epoch [15240], val_loss: 3899.0000\n",
            "Epoch [15260], val_loss: 3904.3000\n",
            "Epoch [15280], val_loss: 3901.3086\n",
            "Epoch [15300], val_loss: 3900.8105\n",
            "Epoch [15320], val_loss: 3904.8625\n",
            "Epoch [15340], val_loss: 3897.2810\n",
            "Epoch [15360], val_loss: 3901.2585\n",
            "Epoch [15380], val_loss: 3907.6721\n",
            "Epoch [15400], val_loss: 3903.9375\n",
            "Epoch [15420], val_loss: 3897.9119\n",
            "Epoch [15440], val_loss: 3893.3438\n",
            "Epoch [15460], val_loss: 3899.1765\n",
            "Epoch [15480], val_loss: 3897.2195\n",
            "Epoch [15500], val_loss: 3902.6873\n",
            "Epoch [15520], val_loss: 3911.7107\n",
            "Epoch [15540], val_loss: 3896.8528\n",
            "Epoch [15560], val_loss: 3902.6497\n",
            "Epoch [15580], val_loss: 3902.1729\n",
            "Epoch [15600], val_loss: 3896.1804\n",
            "Epoch [15620], val_loss: 3893.0603\n",
            "Epoch [15640], val_loss: 3894.0774\n",
            "Epoch [15660], val_loss: 3894.6692\n",
            "Epoch [15680], val_loss: 3895.2903\n",
            "Epoch [15700], val_loss: 3903.0105\n",
            "Epoch [15720], val_loss: 3892.2107\n",
            "Epoch [15740], val_loss: 3897.3574\n",
            "Epoch [15760], val_loss: 3905.4368\n",
            "Epoch [15780], val_loss: 3896.6289\n",
            "Epoch [15800], val_loss: 3897.0139\n",
            "Epoch [15820], val_loss: 3903.6221\n",
            "Epoch [15840], val_loss: 3904.3047\n",
            "Epoch [15860], val_loss: 3901.5481\n",
            "Epoch [15880], val_loss: 3895.5664\n",
            "Epoch [15900], val_loss: 3903.6790\n",
            "Epoch [15920], val_loss: 3906.3762\n",
            "Epoch [15940], val_loss: 3895.7449\n",
            "Epoch [15960], val_loss: 3896.6711\n",
            "Epoch [15980], val_loss: 3898.4031\n",
            "Epoch [16000], val_loss: 3894.4109\n",
            "Epoch [16020], val_loss: 3901.1438\n",
            "Epoch [16040], val_loss: 3904.7922\n",
            "Epoch [16060], val_loss: 3890.4141\n",
            "Epoch [16080], val_loss: 3892.0361\n",
            "Epoch [16100], val_loss: 3892.6526\n",
            "Epoch [16120], val_loss: 3896.9111\n",
            "Epoch [16140], val_loss: 3892.1165\n",
            "Epoch [16160], val_loss: 3911.1609\n",
            "Epoch [16180], val_loss: 3910.6497\n",
            "Epoch [16200], val_loss: 3898.8850\n",
            "Epoch [16220], val_loss: 3918.0371\n",
            "Epoch [16240], val_loss: 3900.7578\n",
            "Epoch [16260], val_loss: 3901.7986\n",
            "Epoch [16280], val_loss: 3898.0085\n",
            "Epoch [16300], val_loss: 3902.0706\n",
            "Epoch [16320], val_loss: 3893.9512\n",
            "Epoch [16340], val_loss: 3909.3918\n",
            "Epoch [16360], val_loss: 3892.6992\n",
            "Epoch [16380], val_loss: 3896.5439\n",
            "Epoch [16400], val_loss: 3893.9714\n",
            "Epoch [16420], val_loss: 3892.6096\n",
            "Epoch [16440], val_loss: 3892.4558\n",
            "Epoch [16460], val_loss: 3897.4929\n",
            "Epoch [16480], val_loss: 3909.8147\n",
            "Epoch [16500], val_loss: 3903.5906\n",
            "Epoch [16520], val_loss: 3909.1914\n",
            "Epoch [16540], val_loss: 3896.9851\n",
            "Epoch [16560], val_loss: 3892.4961\n",
            "Epoch [16580], val_loss: 3900.1028\n",
            "Epoch [16600], val_loss: 3893.1941\n",
            "Epoch [16620], val_loss: 3908.6855\n",
            "Epoch [16640], val_loss: 3896.1855\n",
            "Epoch [16660], val_loss: 3898.3174\n",
            "Epoch [16680], val_loss: 3897.5159\n",
            "Epoch [16700], val_loss: 3889.3557\n",
            "Epoch [16720], val_loss: 3897.1282\n",
            "Epoch [16740], val_loss: 3888.6824\n",
            "Epoch [16760], val_loss: 3900.0266\n",
            "Epoch [16780], val_loss: 3892.2676\n",
            "Epoch [16800], val_loss: 3893.9900\n",
            "Epoch [16820], val_loss: 3899.0254\n",
            "Epoch [16840], val_loss: 3900.0735\n",
            "Epoch [16860], val_loss: 3893.9766\n",
            "Epoch [16880], val_loss: 3889.1511\n",
            "Epoch [16900], val_loss: 3899.8848\n",
            "Epoch [16920], val_loss: 3901.4910\n",
            "Epoch [16940], val_loss: 3898.3533\n",
            "Epoch [16960], val_loss: 3894.4597\n",
            "Epoch [16980], val_loss: 3891.6960\n",
            "Epoch [17000], val_loss: 3894.5710\n",
            "Epoch [17020], val_loss: 3892.6055\n",
            "Epoch [17040], val_loss: 3901.5554\n",
            "Epoch [17060], val_loss: 3902.7019\n",
            "Epoch [17080], val_loss: 3899.6511\n",
            "Epoch [17100], val_loss: 3889.7520\n",
            "Epoch [17120], val_loss: 3898.1707\n",
            "Epoch [17140], val_loss: 3907.6746\n",
            "Epoch [17160], val_loss: 3908.5488\n",
            "Epoch [17180], val_loss: 3891.9404\n",
            "Epoch [17200], val_loss: 3889.8074\n",
            "Epoch [17220], val_loss: 3896.7024\n",
            "Epoch [17240], val_loss: 3900.4597\n",
            "Epoch [17260], val_loss: 3895.0266\n",
            "Epoch [17280], val_loss: 3912.0833\n",
            "Epoch [17300], val_loss: 3891.3821\n",
            "Epoch [17320], val_loss: 3888.8093\n",
            "Epoch [17340], val_loss: 3891.1660\n",
            "Epoch [17360], val_loss: 3894.2214\n",
            "Epoch [17380], val_loss: 3893.6309\n",
            "Epoch [17400], val_loss: 3892.9209\n",
            "Epoch [17420], val_loss: 3895.6775\n",
            "Epoch [17440], val_loss: 3888.1848\n",
            "Epoch [17460], val_loss: 3888.9661\n",
            "Epoch [17480], val_loss: 3891.6289\n",
            "Epoch [17500], val_loss: 3895.2727\n",
            "Epoch [17520], val_loss: 3892.1433\n",
            "Epoch [17540], val_loss: 3887.1111\n",
            "Epoch [17560], val_loss: 3897.5293\n",
            "Epoch [17580], val_loss: 3911.3855\n",
            "Epoch [17600], val_loss: 3895.8098\n",
            "Epoch [17620], val_loss: 3898.1648\n",
            "Epoch [17640], val_loss: 3887.9355\n",
            "Epoch [17660], val_loss: 3892.9395\n",
            "Epoch [17680], val_loss: 3901.1484\n",
            "Epoch [17700], val_loss: 3898.6555\n",
            "Epoch [17720], val_loss: 3892.5281\n",
            "Epoch [17740], val_loss: 3899.6653\n",
            "Epoch [17760], val_loss: 3896.9348\n",
            "Epoch [17780], val_loss: 3896.9963\n",
            "Epoch [17800], val_loss: 3893.6543\n",
            "Epoch [17820], val_loss: 3885.5305\n",
            "Epoch [17840], val_loss: 3890.5828\n",
            "Epoch [17860], val_loss: 3892.8516\n",
            "Epoch [17880], val_loss: 3902.0134\n",
            "Epoch [17900], val_loss: 3893.1416\n",
            "Epoch [17920], val_loss: 3892.1541\n",
            "Epoch [17940], val_loss: 3888.0945\n",
            "Epoch [17960], val_loss: 3888.3926\n",
            "Epoch [17980], val_loss: 3896.3926\n",
            "Epoch [18000], val_loss: 3894.3738\n",
            "Epoch [18020], val_loss: 3893.3162\n",
            "Epoch [18040], val_loss: 3892.5645\n",
            "Epoch [18060], val_loss: 3899.5911\n",
            "Epoch [18080], val_loss: 3888.0950\n",
            "Epoch [18100], val_loss: 3893.0312\n",
            "Epoch [18120], val_loss: 3913.1809\n",
            "Epoch [18140], val_loss: 3887.0710\n",
            "Epoch [18160], val_loss: 3891.6746\n",
            "Epoch [18180], val_loss: 3888.1223\n",
            "Epoch [18200], val_loss: 3895.4460\n",
            "Epoch [18220], val_loss: 3893.6172\n",
            "Epoch [18240], val_loss: 3890.1531\n",
            "Epoch [18260], val_loss: 3892.3508\n",
            "Epoch [18280], val_loss: 3900.4172\n",
            "Epoch [18300], val_loss: 3889.2188\n",
            "Epoch [18320], val_loss: 3898.4226\n",
            "Epoch [18340], val_loss: 3895.1814\n",
            "Epoch [18360], val_loss: 3903.8184\n",
            "Epoch [18380], val_loss: 3890.0442\n",
            "Epoch [18400], val_loss: 3890.7185\n",
            "Epoch [18420], val_loss: 3894.9600\n",
            "Epoch [18440], val_loss: 3893.4619\n",
            "Epoch [18460], val_loss: 3904.2070\n",
            "Epoch [18480], val_loss: 3908.5586\n",
            "Epoch [18500], val_loss: 3891.0312\n",
            "Epoch [18520], val_loss: 3887.2090\n",
            "Epoch [18540], val_loss: 3890.2043\n",
            "Epoch [18560], val_loss: 3888.3440\n",
            "Epoch [18580], val_loss: 3889.9031\n",
            "Epoch [18600], val_loss: 3888.2483\n",
            "Epoch [18620], val_loss: 3886.7012\n",
            "Epoch [18640], val_loss: 3887.4612\n",
            "Epoch [18660], val_loss: 3894.2412\n",
            "Epoch [18680], val_loss: 3891.1367\n",
            "Epoch [18700], val_loss: 3890.1609\n",
            "Epoch [18720], val_loss: 3890.6934\n",
            "Epoch [18740], val_loss: 3891.0886\n",
            "Epoch [18760], val_loss: 3891.4270\n",
            "Epoch [18780], val_loss: 3887.6843\n",
            "Epoch [18800], val_loss: 3901.6106\n",
            "Epoch [18820], val_loss: 3897.9231\n",
            "Epoch [18840], val_loss: 3890.5891\n",
            "Epoch [18860], val_loss: 3889.2180\n",
            "Epoch [18880], val_loss: 3896.6250\n",
            "Epoch [18900], val_loss: 3902.5129\n",
            "Epoch [18920], val_loss: 3887.8918\n",
            "Epoch [18940], val_loss: 3891.4910\n",
            "Epoch [18960], val_loss: 3887.4805\n",
            "Epoch [18980], val_loss: 3884.7773\n",
            "Epoch [19000], val_loss: 3891.4270\n",
            "Epoch [19020], val_loss: 3888.0432\n",
            "Epoch [19040], val_loss: 3893.9534\n",
            "Epoch [19060], val_loss: 3887.5254\n",
            "Epoch [19080], val_loss: 3886.3777\n",
            "Epoch [19100], val_loss: 3890.7644\n",
            "Epoch [19120], val_loss: 3890.4912\n",
            "Epoch [19140], val_loss: 3901.5657\n",
            "Epoch [19160], val_loss: 3896.4602\n",
            "Epoch [19180], val_loss: 3893.2161\n",
            "Epoch [19200], val_loss: 3888.7312\n",
            "Epoch [19220], val_loss: 3896.9519\n",
            "Epoch [19240], val_loss: 3886.4822\n",
            "Epoch [19260], val_loss: 3885.2021\n",
            "Epoch [19280], val_loss: 3895.6091\n",
            "Epoch [19300], val_loss: 3902.5691\n",
            "Epoch [19320], val_loss: 3886.2683\n",
            "Epoch [19340], val_loss: 3886.7961\n",
            "Epoch [19360], val_loss: 3888.8750\n",
            "Epoch [19380], val_loss: 3887.8184\n",
            "Epoch [19400], val_loss: 3892.1624\n",
            "Epoch [19420], val_loss: 3893.7595\n",
            "Epoch [19440], val_loss: 3891.8899\n",
            "Epoch [19460], val_loss: 3900.4519\n",
            "Epoch [19480], val_loss: 3893.4111\n",
            "Epoch [19500], val_loss: 3891.5117\n",
            "Epoch [19520], val_loss: 3894.0918\n",
            "Epoch [19540], val_loss: 3885.9358\n",
            "Epoch [19560], val_loss: 3892.7234\n",
            "Epoch [19580], val_loss: 3890.3494\n",
            "Epoch [19600], val_loss: 3898.7224\n",
            "Epoch [19620], val_loss: 3884.4004\n",
            "Epoch [19640], val_loss: 3885.5417\n",
            "Epoch [19660], val_loss: 3892.6555\n",
            "Epoch [19680], val_loss: 3889.2395\n",
            "Epoch [19700], val_loss: 3904.0671\n",
            "Epoch [19720], val_loss: 3891.8464\n",
            "Epoch [19740], val_loss: 3897.5537\n",
            "Epoch [19760], val_loss: 3890.4534\n",
            "Epoch [19780], val_loss: 3888.5234\n",
            "Epoch [19800], val_loss: 3885.7063\n",
            "Epoch [19820], val_loss: 3896.3438\n",
            "Epoch [19840], val_loss: 3890.1445\n",
            "Epoch [19860], val_loss: 3886.0525\n",
            "Epoch [19880], val_loss: 3893.0032\n",
            "Epoch [19900], val_loss: 3888.9426\n",
            "Epoch [19920], val_loss: 3889.2971\n",
            "Epoch [19940], val_loss: 3893.7793\n",
            "Epoch [19960], val_loss: 3896.6472\n",
            "Epoch [19980], val_loss: 3890.6360\n",
            "Epoch [20000], val_loss: 3891.5706\n",
            "Epoch [20020], val_loss: 3884.1865\n",
            "Epoch [20040], val_loss: 3892.8840\n",
            "Epoch [20060], val_loss: 3906.8601\n",
            "Epoch [20080], val_loss: 3895.1553\n",
            "Epoch [20100], val_loss: 3900.0017\n",
            "Epoch [20120], val_loss: 3886.3789\n",
            "Epoch [20140], val_loss: 3887.0879\n",
            "Epoch [20160], val_loss: 3891.0957\n",
            "Epoch [20180], val_loss: 3882.4612\n",
            "Epoch [20200], val_loss: 3891.7625\n",
            "Epoch [20220], val_loss: 3894.6035\n",
            "Epoch [20240], val_loss: 3884.5371\n",
            "Epoch [20260], val_loss: 3887.1248\n",
            "Epoch [20280], val_loss: 3898.9141\n",
            "Epoch [20300], val_loss: 3891.3486\n",
            "Epoch [20320], val_loss: 3888.7898\n",
            "Epoch [20340], val_loss: 3891.8762\n",
            "Epoch [20360], val_loss: 3898.1096\n",
            "Epoch [20380], val_loss: 3887.9656\n",
            "Epoch [20400], val_loss: 3889.8870\n",
            "Epoch [20420], val_loss: 3884.2522\n",
            "Epoch [20440], val_loss: 3887.5339\n",
            "Epoch [20460], val_loss: 3884.7976\n",
            "Epoch [20480], val_loss: 3902.3733\n",
            "Epoch [20500], val_loss: 3895.5769\n",
            "Epoch [20520], val_loss: 3890.7786\n",
            "Epoch [20540], val_loss: 3895.0137\n",
            "Epoch [20560], val_loss: 3893.4700\n",
            "Epoch [20580], val_loss: 3901.0742\n",
            "Epoch [20600], val_loss: 3894.3848\n",
            "Epoch [20620], val_loss: 3892.2961\n",
            "Epoch [20640], val_loss: 3895.9929\n",
            "Epoch [20660], val_loss: 3900.1797\n",
            "Epoch [20680], val_loss: 3888.1497\n",
            "Epoch [20700], val_loss: 3885.7151\n",
            "Epoch [20720], val_loss: 3889.6536\n",
            "Epoch [20740], val_loss: 3883.2595\n",
            "Epoch [20760], val_loss: 3888.0535\n",
            "Epoch [20780], val_loss: 3901.3684\n",
            "Epoch [20800], val_loss: 3881.8125\n",
            "Epoch [20820], val_loss: 3887.2278\n",
            "Epoch [20840], val_loss: 3886.6165\n",
            "Epoch [20860], val_loss: 3901.0042\n",
            "Epoch [20880], val_loss: 3882.4473\n",
            "Epoch [20900], val_loss: 3885.8220\n",
            "Epoch [20920], val_loss: 3897.8093\n",
            "Epoch [20940], val_loss: 3894.3477\n",
            "Epoch [20960], val_loss: 3888.9407\n",
            "Epoch [20980], val_loss: 3887.6787\n",
            "Epoch [21000], val_loss: 3884.3679\n",
            "Epoch [21020], val_loss: 3889.7012\n",
            "Epoch [21040], val_loss: 3896.5237\n",
            "Epoch [21060], val_loss: 3901.1135\n",
            "Epoch [21080], val_loss: 3888.7063\n",
            "Epoch [21100], val_loss: 3880.7195\n",
            "Epoch [21120], val_loss: 3891.7063\n",
            "Epoch [21140], val_loss: 3883.2073\n",
            "Epoch [21160], val_loss: 3894.8733\n",
            "Epoch [21180], val_loss: 3892.3147\n",
            "Epoch [21200], val_loss: 3900.1477\n",
            "Epoch [21220], val_loss: 3883.9392\n",
            "Epoch [21240], val_loss: 3884.3953\n",
            "Epoch [21260], val_loss: 3884.7493\n",
            "Epoch [21280], val_loss: 3906.2432\n",
            "Epoch [21300], val_loss: 3893.0559\n",
            "Epoch [21320], val_loss: 3902.8301\n",
            "Epoch [21340], val_loss: 3890.9824\n",
            "Epoch [21360], val_loss: 3882.0488\n",
            "Epoch [21380], val_loss: 3891.0051\n",
            "Epoch [21400], val_loss: 3888.9871\n",
            "Epoch [21420], val_loss: 3889.2004\n",
            "Epoch [21440], val_loss: 3893.8743\n",
            "Epoch [21460], val_loss: 3883.8625\n",
            "Epoch [21480], val_loss: 3890.8850\n",
            "Epoch [21500], val_loss: 3886.2478\n",
            "Epoch [21520], val_loss: 3885.3555\n",
            "Epoch [21540], val_loss: 3891.9902\n",
            "Epoch [21560], val_loss: 3899.5520\n",
            "Epoch [21580], val_loss: 3882.1692\n",
            "Epoch [21600], val_loss: 3891.1633\n",
            "Epoch [21620], val_loss: 3884.9812\n",
            "Epoch [21640], val_loss: 3894.3699\n",
            "Epoch [21660], val_loss: 3884.9714\n",
            "Epoch [21680], val_loss: 3895.7346\n",
            "Epoch [21700], val_loss: 3893.4990\n",
            "Epoch [21720], val_loss: 3887.7722\n",
            "Epoch [21740], val_loss: 3888.6653\n",
            "Epoch [21760], val_loss: 3882.8342\n",
            "Epoch [21780], val_loss: 3883.2256\n",
            "Epoch [21800], val_loss: 3893.9277\n",
            "Epoch [21820], val_loss: 3892.4326\n",
            "Epoch [21840], val_loss: 3885.1003\n",
            "Epoch [21860], val_loss: 3884.6414\n",
            "Epoch [21880], val_loss: 3886.1787\n",
            "Epoch [21900], val_loss: 3878.1924\n",
            "Epoch [21920], val_loss: 3899.9990\n",
            "Epoch [21940], val_loss: 3888.1614\n",
            "Epoch [21960], val_loss: 3884.1121\n",
            "Epoch [21980], val_loss: 3880.9583\n",
            "Epoch [22000], val_loss: 3882.1641\n",
            "Epoch [22020], val_loss: 3885.9680\n",
            "Epoch [22040], val_loss: 3900.5859\n",
            "Epoch [22060], val_loss: 3888.3411\n",
            "Epoch [22080], val_loss: 3878.8235\n",
            "Epoch [22100], val_loss: 3884.5369\n",
            "Epoch [22120], val_loss: 3900.5596\n",
            "Epoch [22140], val_loss: 3882.6086\n",
            "Epoch [22160], val_loss: 3882.4236\n",
            "Epoch [22180], val_loss: 3890.7314\n",
            "Epoch [22200], val_loss: 3892.4421\n",
            "Epoch [22220], val_loss: 3880.9968\n",
            "Epoch [22240], val_loss: 3883.2312\n",
            "Epoch [22260], val_loss: 3883.2122\n",
            "Epoch [22280], val_loss: 3880.7395\n",
            "Epoch [22300], val_loss: 3886.9373\n",
            "Epoch [22320], val_loss: 3891.6316\n",
            "Epoch [22340], val_loss: 3900.9875\n",
            "Epoch [22360], val_loss: 3882.9072\n",
            "Epoch [22380], val_loss: 3879.8855\n",
            "Epoch [22400], val_loss: 3889.6223\n",
            "Epoch [22420], val_loss: 3885.1426\n",
            "Epoch [22440], val_loss: 3885.3245\n",
            "Epoch [22460], val_loss: 3892.2942\n",
            "Epoch [22480], val_loss: 3883.6895\n",
            "Epoch [22500], val_loss: 3885.5049\n",
            "Epoch [22520], val_loss: 3880.0957\n",
            "Epoch [22540], val_loss: 3879.4910\n",
            "Epoch [22560], val_loss: 3883.5281\n",
            "Epoch [22580], val_loss: 3892.7000\n",
            "Epoch [22600], val_loss: 3891.2000\n",
            "Epoch [22620], val_loss: 3882.5898\n",
            "Epoch [22640], val_loss: 3885.1458\n",
            "Epoch [22660], val_loss: 3893.3132\n",
            "Epoch [22680], val_loss: 3888.6047\n",
            "Epoch [22700], val_loss: 3888.4187\n",
            "Epoch [22720], val_loss: 3880.9629\n",
            "Epoch [22740], val_loss: 3891.1101\n",
            "Epoch [22760], val_loss: 3892.6233\n",
            "Epoch [22780], val_loss: 3887.1594\n",
            "Epoch [22800], val_loss: 3887.4600\n",
            "Epoch [22820], val_loss: 3881.6711\n",
            "Epoch [22840], val_loss: 3882.6367\n",
            "Epoch [22860], val_loss: 3882.9407\n",
            "Epoch [22880], val_loss: 3884.7825\n",
            "Epoch [22900], val_loss: 3894.2937\n",
            "Epoch [22920], val_loss: 3880.4890\n",
            "Epoch [22940], val_loss: 3889.3408\n",
            "Epoch [22960], val_loss: 3889.5627\n",
            "Epoch [22980], val_loss: 3881.1123\n",
            "Epoch [23000], val_loss: 3880.6738\n",
            "Epoch [23020], val_loss: 3881.9348\n",
            "Epoch [23040], val_loss: 3880.5886\n",
            "Epoch [23060], val_loss: 3883.3909\n",
            "Epoch [23080], val_loss: 3879.2410\n",
            "Epoch [23100], val_loss: 3877.7805\n",
            "Epoch [23120], val_loss: 3882.9895\n",
            "Epoch [23140], val_loss: 3885.2520\n",
            "Epoch [23160], val_loss: 3887.5334\n",
            "Epoch [23180], val_loss: 3887.1396\n",
            "Epoch [23200], val_loss: 3894.5793\n",
            "Epoch [23220], val_loss: 3890.0342\n",
            "Epoch [23240], val_loss: 3877.8547\n",
            "Epoch [23260], val_loss: 3878.5205\n",
            "Epoch [23280], val_loss: 3878.8796\n",
            "Epoch [23300], val_loss: 3902.5950\n",
            "Epoch [23320], val_loss: 3883.4114\n",
            "Epoch [23340], val_loss: 3895.6738\n",
            "Epoch [23360], val_loss: 3890.8542\n",
            "Epoch [23380], val_loss: 3882.8245\n",
            "Epoch [23400], val_loss: 3890.9402\n",
            "Epoch [23420], val_loss: 3890.3933\n",
            "Epoch [23440], val_loss: 3892.3359\n",
            "Epoch [23460], val_loss: 3894.9812\n",
            "Epoch [23480], val_loss: 3891.3496\n",
            "Epoch [23500], val_loss: 3885.5203\n",
            "Epoch [23520], val_loss: 3878.0261\n",
            "Epoch [23540], val_loss: 3879.4629\n",
            "Epoch [23560], val_loss: 3889.2957\n",
            "Epoch [23580], val_loss: 3891.0496\n",
            "Epoch [23600], val_loss: 3890.3738\n",
            "Epoch [23620], val_loss: 3883.6667\n",
            "Epoch [23640], val_loss: 3886.5515\n",
            "Epoch [23660], val_loss: 3879.9456\n",
            "Epoch [23680], val_loss: 3884.7161\n",
            "Epoch [23700], val_loss: 3888.6726\n",
            "Epoch [23720], val_loss: 3884.9856\n",
            "Epoch [23740], val_loss: 3882.0164\n",
            "Epoch [23760], val_loss: 3879.9099\n",
            "Epoch [23780], val_loss: 3881.0205\n",
            "Epoch [23800], val_loss: 3886.6270\n",
            "Epoch [23820], val_loss: 3880.8750\n",
            "Epoch [23840], val_loss: 3886.7156\n",
            "Epoch [23860], val_loss: 3885.1614\n",
            "Epoch [23880], val_loss: 3886.8035\n",
            "Epoch [23900], val_loss: 3881.5657\n",
            "Epoch [23920], val_loss: 3891.2908\n",
            "Epoch [23940], val_loss: 3880.5371\n",
            "Epoch [23960], val_loss: 3881.9436\n",
            "Epoch [23980], val_loss: 3890.1438\n",
            "Epoch [24000], val_loss: 3878.0242\n",
            "Epoch [24020], val_loss: 3880.8772\n",
            "Epoch [24040], val_loss: 3889.7256\n",
            "Epoch [24060], val_loss: 3895.0598\n",
            "Epoch [24080], val_loss: 3887.5632\n",
            "Epoch [24100], val_loss: 3877.9812\n",
            "Epoch [24120], val_loss: 3882.1152\n",
            "Epoch [24140], val_loss: 3890.0930\n",
            "Epoch [24160], val_loss: 3886.0691\n",
            "Epoch [24180], val_loss: 3881.4250\n",
            "Epoch [24200], val_loss: 3894.9424\n",
            "Epoch [24220], val_loss: 3889.3447\n",
            "Epoch [24240], val_loss: 3885.3489\n",
            "Epoch [24260], val_loss: 3880.6680\n",
            "Epoch [24280], val_loss: 3884.2322\n",
            "Epoch [24300], val_loss: 3889.6746\n",
            "Epoch [24320], val_loss: 3890.3992\n",
            "Epoch [24340], val_loss: 3880.9082\n",
            "Epoch [24360], val_loss: 3883.5496\n",
            "Epoch [24380], val_loss: 3887.2236\n",
            "Epoch [24400], val_loss: 3884.2952\n",
            "Epoch [24420], val_loss: 3874.6726\n",
            "Epoch [24440], val_loss: 3897.0808\n",
            "Epoch [24460], val_loss: 3890.7219\n",
            "Epoch [24480], val_loss: 3880.5144\n",
            "Epoch [24500], val_loss: 3882.5457\n",
            "Epoch [24520], val_loss: 3892.3789\n",
            "Epoch [24540], val_loss: 3883.4160\n",
            "Epoch [24560], val_loss: 3882.1699\n",
            "Epoch [24580], val_loss: 3881.0774\n",
            "Epoch [24600], val_loss: 3895.9773\n",
            "Epoch [24620], val_loss: 3884.2039\n",
            "Epoch [24640], val_loss: 3890.3613\n",
            "Epoch [24660], val_loss: 3886.7234\n",
            "Epoch [24680], val_loss: 3883.7520\n",
            "Epoch [24700], val_loss: 3892.9172\n",
            "Epoch [24720], val_loss: 3885.8789\n",
            "Epoch [24740], val_loss: 3886.7688\n",
            "Epoch [24760], val_loss: 3882.9727\n",
            "Epoch [24780], val_loss: 3880.9192\n",
            "Epoch [24800], val_loss: 3879.0273\n",
            "Epoch [24820], val_loss: 3875.5261\n",
            "Epoch [24840], val_loss: 3877.2468\n",
            "Epoch [24860], val_loss: 3889.7659\n",
            "Epoch [24880], val_loss: 3886.2090\n",
            "Epoch [24900], val_loss: 3882.5984\n",
            "Epoch [24920], val_loss: 3880.9590\n",
            "Epoch [24940], val_loss: 3881.3066\n",
            "Epoch [24960], val_loss: 3891.0645\n",
            "Epoch [24980], val_loss: 3886.0461\n",
            "Epoch [25000], val_loss: 3881.8164\n",
            "Epoch [25020], val_loss: 3889.7234\n",
            "Epoch [25040], val_loss: 3876.1836\n",
            "Epoch [25060], val_loss: 3883.9355\n",
            "Epoch [25080], val_loss: 3895.2825\n",
            "Epoch [25100], val_loss: 3877.9783\n",
            "Epoch [25120], val_loss: 3877.5320\n",
            "Epoch [25140], val_loss: 3893.2539\n",
            "Epoch [25160], val_loss: 3880.5437\n",
            "Epoch [25180], val_loss: 3880.1953\n",
            "Epoch [25200], val_loss: 3873.3860\n",
            "Epoch [25220], val_loss: 3883.6260\n",
            "Epoch [25240], val_loss: 3875.0095\n",
            "Epoch [25260], val_loss: 3878.2942\n",
            "Epoch [25280], val_loss: 3884.3428\n",
            "Epoch [25300], val_loss: 3877.1423\n",
            "Epoch [25320], val_loss: 3897.6047\n",
            "Epoch [25340], val_loss: 3882.2332\n",
            "Epoch [25360], val_loss: 3880.5867\n",
            "Epoch [25380], val_loss: 3874.2383\n",
            "Epoch [25400], val_loss: 3877.6863\n",
            "Epoch [25420], val_loss: 3882.7185\n",
            "Epoch [25440], val_loss: 3878.6680\n",
            "Epoch [25460], val_loss: 3887.6667\n",
            "Epoch [25480], val_loss: 3877.1433\n",
            "Epoch [25500], val_loss: 3888.1445\n",
            "Epoch [25520], val_loss: 3886.8359\n",
            "Epoch [25540], val_loss: 3876.7512\n",
            "Epoch [25560], val_loss: 3886.5002\n",
            "Epoch [25580], val_loss: 3879.7393\n",
            "Epoch [25600], val_loss: 3884.8679\n",
            "Epoch [25620], val_loss: 3878.8992\n",
            "Epoch [25640], val_loss: 3882.6621\n",
            "Epoch [25660], val_loss: 3890.6497\n",
            "Epoch [25680], val_loss: 3879.1289\n",
            "Epoch [25700], val_loss: 3876.8923\n",
            "Epoch [25720], val_loss: 3877.7610\n",
            "Epoch [25740], val_loss: 3886.7800\n",
            "Epoch [25760], val_loss: 3872.5159\n",
            "Epoch [25780], val_loss: 3886.6287\n",
            "Epoch [25800], val_loss: 3888.9934\n",
            "Epoch [25820], val_loss: 3887.2263\n",
            "Epoch [25840], val_loss: 3892.9973\n",
            "Epoch [25860], val_loss: 3889.3074\n",
            "Epoch [25880], val_loss: 3882.9258\n",
            "Epoch [25900], val_loss: 3874.4768\n",
            "Epoch [25920], val_loss: 3898.1345\n",
            "Epoch [25940], val_loss: 3878.5547\n",
            "Epoch [25960], val_loss: 3894.0295\n",
            "Epoch [25980], val_loss: 3881.8621\n",
            "Epoch [26000], val_loss: 3877.7683\n",
            "Epoch [26020], val_loss: 3895.2991\n",
            "Epoch [26040], val_loss: 3876.3691\n",
            "Epoch [26060], val_loss: 3888.6609\n",
            "Epoch [26080], val_loss: 3878.8457\n",
            "Epoch [26100], val_loss: 3877.5564\n",
            "Epoch [26120], val_loss: 3888.9707\n",
            "Epoch [26140], val_loss: 3877.5554\n",
            "Epoch [26160], val_loss: 3885.4375\n",
            "Epoch [26180], val_loss: 3878.1699\n",
            "Epoch [26200], val_loss: 3880.6113\n",
            "Epoch [26220], val_loss: 3879.2322\n",
            "Epoch [26240], val_loss: 3874.7664\n",
            "Epoch [26260], val_loss: 3890.0701\n",
            "Epoch [26280], val_loss: 3880.5461\n",
            "Epoch [26300], val_loss: 3877.4492\n",
            "Epoch [26320], val_loss: 3892.8328\n",
            "Epoch [26340], val_loss: 3879.4788\n",
            "Epoch [26360], val_loss: 3885.2207\n",
            "Epoch [26380], val_loss: 3871.7141\n",
            "Epoch [26400], val_loss: 3889.1016\n",
            "Epoch [26420], val_loss: 3878.8508\n",
            "Epoch [26440], val_loss: 3879.5076\n",
            "Epoch [26460], val_loss: 3887.4023\n",
            "Epoch [26480], val_loss: 3881.1992\n",
            "Epoch [26500], val_loss: 3877.6758\n",
            "Epoch [26520], val_loss: 3880.9060\n",
            "Epoch [26540], val_loss: 3875.8835\n",
            "Epoch [26560], val_loss: 3878.8665\n",
            "Epoch [26580], val_loss: 3887.7434\n",
            "Epoch [26600], val_loss: 3884.9805\n",
            "Epoch [26620], val_loss: 3885.6172\n",
            "Epoch [26640], val_loss: 3878.6897\n",
            "Epoch [26660], val_loss: 3885.9387\n",
            "Epoch [26680], val_loss: 3889.9968\n",
            "Epoch [26700], val_loss: 3887.9856\n",
            "Epoch [26720], val_loss: 3874.3828\n",
            "Epoch [26740], val_loss: 3879.3191\n",
            "Epoch [26760], val_loss: 3881.1162\n",
            "Epoch [26780], val_loss: 3872.7168\n",
            "Epoch [26800], val_loss: 3886.5459\n",
            "Epoch [26820], val_loss: 3874.2200\n",
            "Epoch [26840], val_loss: 3892.1865\n",
            "Epoch [26860], val_loss: 3877.1360\n",
            "Epoch [26880], val_loss: 3875.6692\n",
            "Epoch [26900], val_loss: 3875.3281\n",
            "Epoch [26920], val_loss: 3875.5320\n",
            "Epoch [26940], val_loss: 3872.2683\n",
            "Epoch [26960], val_loss: 3881.0032\n",
            "Epoch [26980], val_loss: 3873.7878\n",
            "Epoch [27000], val_loss: 3881.2754\n",
            "Epoch [27020], val_loss: 3879.6758\n",
            "Epoch [27040], val_loss: 3872.7266\n",
            "Epoch [27060], val_loss: 3875.2898\n",
            "Epoch [27080], val_loss: 3875.9011\n",
            "Epoch [27100], val_loss: 3874.8098\n",
            "Epoch [27120], val_loss: 3878.3477\n",
            "Epoch [27140], val_loss: 3883.7747\n",
            "Epoch [27160], val_loss: 3876.4583\n",
            "Epoch [27180], val_loss: 3885.8743\n",
            "Epoch [27200], val_loss: 3879.6621\n",
            "Epoch [27220], val_loss: 3876.0703\n",
            "Epoch [27240], val_loss: 3883.2507\n",
            "Epoch [27260], val_loss: 3883.6799\n",
            "Epoch [27280], val_loss: 3884.1199\n",
            "Epoch [27300], val_loss: 3875.6338\n",
            "Epoch [27320], val_loss: 3872.5020\n",
            "Epoch [27340], val_loss: 3876.2976\n",
            "Epoch [27360], val_loss: 3885.3738\n",
            "Epoch [27380], val_loss: 3873.5525\n",
            "Epoch [27400], val_loss: 3884.8196\n",
            "Epoch [27420], val_loss: 3886.5618\n",
            "Epoch [27440], val_loss: 3870.1006\n",
            "Epoch [27460], val_loss: 3883.3284\n",
            "Epoch [27480], val_loss: 3885.5715\n",
            "Epoch [27500], val_loss: 3880.0105\n",
            "Epoch [27520], val_loss: 3889.7566\n",
            "Epoch [27540], val_loss: 3872.0857\n",
            "Epoch [27560], val_loss: 3891.8308\n",
            "Epoch [27580], val_loss: 3884.9480\n",
            "Epoch [27600], val_loss: 3875.2073\n",
            "Epoch [27620], val_loss: 3876.3254\n",
            "Epoch [27640], val_loss: 3872.8938\n",
            "Epoch [27660], val_loss: 3882.4368\n",
            "Epoch [27680], val_loss: 3883.5605\n",
            "Epoch [27700], val_loss: 3874.1367\n",
            "Epoch [27720], val_loss: 3890.7278\n",
            "Epoch [27740], val_loss: 3879.0359\n",
            "Epoch [27760], val_loss: 3882.2039\n",
            "Epoch [27780], val_loss: 3879.0059\n",
            "Epoch [27800], val_loss: 3875.1680\n",
            "Epoch [27820], val_loss: 3879.8906\n",
            "Epoch [27840], val_loss: 3877.1355\n",
            "Epoch [27860], val_loss: 3884.0779\n",
            "Epoch [27880], val_loss: 3872.7517\n",
            "Epoch [27900], val_loss: 3873.8455\n",
            "Epoch [27920], val_loss: 3873.3281\n",
            "Epoch [27940], val_loss: 3882.0227\n",
            "Epoch [27960], val_loss: 3876.6270\n",
            "Epoch [27980], val_loss: 3872.8738\n",
            "Epoch [28000], val_loss: 3882.2625\n",
            "Epoch [28020], val_loss: 3874.1760\n",
            "Epoch [28040], val_loss: 3879.1550\n",
            "Epoch [28060], val_loss: 3888.0105\n",
            "Epoch [28080], val_loss: 3872.4219\n",
            "Epoch [28100], val_loss: 3873.8281\n",
            "Epoch [28120], val_loss: 3871.7151\n",
            "Epoch [28140], val_loss: 3880.8840\n",
            "Epoch [28160], val_loss: 3876.7742\n",
            "Epoch [28180], val_loss: 3883.5896\n",
            "Epoch [28200], val_loss: 3878.2930\n",
            "Epoch [28220], val_loss: 3875.6963\n",
            "Epoch [28240], val_loss: 3881.5667\n",
            "Epoch [28260], val_loss: 3868.9553\n",
            "Epoch [28280], val_loss: 3883.9961\n",
            "Epoch [28300], val_loss: 3887.6965\n",
            "Epoch [28320], val_loss: 3869.7190\n",
            "Epoch [28340], val_loss: 3872.6936\n",
            "Epoch [28360], val_loss: 3875.3945\n",
            "Epoch [28380], val_loss: 3873.9160\n",
            "Epoch [28400], val_loss: 3871.8762\n",
            "Epoch [28420], val_loss: 3875.2864\n",
            "Epoch [28440], val_loss: 3873.8435\n",
            "Epoch [28460], val_loss: 3874.0935\n",
            "Epoch [28480], val_loss: 3882.4043\n",
            "Epoch [28500], val_loss: 3881.0840\n",
            "Epoch [28520], val_loss: 3877.6553\n",
            "Epoch [28540], val_loss: 3874.5312\n",
            "Epoch [28560], val_loss: 3877.3660\n",
            "Epoch [28580], val_loss: 3874.9172\n",
            "Epoch [28600], val_loss: 3879.6387\n",
            "Epoch [28620], val_loss: 3868.1589\n",
            "Epoch [28640], val_loss: 3879.4636\n",
            "Epoch [28660], val_loss: 3879.6113\n",
            "Epoch [28680], val_loss: 3873.4033\n",
            "Epoch [28700], val_loss: 3871.9231\n",
            "Epoch [28720], val_loss: 3880.1914\n",
            "Epoch [28740], val_loss: 3878.7039\n",
            "Epoch [28760], val_loss: 3873.0051\n",
            "Epoch [28780], val_loss: 3877.3047\n",
            "Epoch [28800], val_loss: 3891.1882\n",
            "Epoch [28820], val_loss: 3875.1550\n",
            "Epoch [28840], val_loss: 3872.6614\n",
            "Epoch [28860], val_loss: 3873.6287\n",
            "Epoch [28880], val_loss: 3873.8167\n",
            "Epoch [28900], val_loss: 3893.4407\n",
            "Epoch [28920], val_loss: 3879.3555\n",
            "Epoch [28940], val_loss: 3872.1855\n",
            "Epoch [28960], val_loss: 3872.1365\n",
            "Epoch [28980], val_loss: 3881.7195\n",
            "Epoch [29000], val_loss: 3878.1199\n",
            "Epoch [29020], val_loss: 3871.4324\n",
            "Epoch [29040], val_loss: 3879.0071\n",
            "Epoch [29060], val_loss: 3873.5095\n",
            "Epoch [29080], val_loss: 3880.1184\n",
            "Epoch [29100], val_loss: 3883.5828\n",
            "Epoch [29120], val_loss: 3871.1340\n",
            "Epoch [29140], val_loss: 3880.1316\n",
            "Epoch [29160], val_loss: 3882.3186\n",
            "Epoch [29180], val_loss: 3873.3733\n",
            "Epoch [29200], val_loss: 3875.8342\n",
            "Epoch [29220], val_loss: 3879.4446\n",
            "Epoch [29240], val_loss: 3876.6985\n",
            "Epoch [29260], val_loss: 3879.9055\n",
            "Epoch [29280], val_loss: 3877.2136\n",
            "Epoch [29300], val_loss: 3870.4941\n",
            "Epoch [29320], val_loss: 3881.1836\n",
            "Epoch [29340], val_loss: 3871.0378\n",
            "Epoch [29360], val_loss: 3878.7246\n",
            "Epoch [29380], val_loss: 3873.7546\n",
            "Epoch [29400], val_loss: 3881.1399\n",
            "Epoch [29420], val_loss: 3871.6377\n",
            "Epoch [29440], val_loss: 3874.2200\n",
            "Epoch [29460], val_loss: 3868.7715\n",
            "Epoch [29480], val_loss: 3888.4404\n",
            "Epoch [29500], val_loss: 3869.5020\n",
            "Epoch [29520], val_loss: 3872.2871\n",
            "Epoch [29540], val_loss: 3871.3389\n",
            "Epoch [29560], val_loss: 3876.6396\n",
            "Epoch [29580], val_loss: 3870.7073\n",
            "Epoch [29600], val_loss: 3869.8098\n",
            "Epoch [29620], val_loss: 3883.6667\n",
            "Epoch [29640], val_loss: 3869.2693\n",
            "Epoch [29660], val_loss: 3875.1692\n",
            "Epoch [29680], val_loss: 3879.8098\n",
            "Epoch [29700], val_loss: 3873.1550\n",
            "Epoch [29720], val_loss: 3871.1228\n",
            "Epoch [29740], val_loss: 3872.9812\n",
            "Epoch [29760], val_loss: 3884.2141\n",
            "Epoch [29780], val_loss: 3880.2871\n",
            "Epoch [29800], val_loss: 3877.7668\n",
            "Epoch [29820], val_loss: 3874.7695\n",
            "Epoch [29840], val_loss: 3875.9199\n",
            "Epoch [29860], val_loss: 3874.5374\n",
            "Epoch [29880], val_loss: 3879.1309\n",
            "Epoch [29900], val_loss: 3877.5469\n",
            "Epoch [29920], val_loss: 3880.6531\n",
            "Epoch [29940], val_loss: 3868.3176\n",
            "Epoch [29960], val_loss: 3869.6211\n",
            "Epoch [29980], val_loss: 3872.0085\n",
            "Epoch [30000], val_loss: 3878.2268\n",
            "Epoch [30020], val_loss: 3878.0793\n",
            "Epoch [30040], val_loss: 3876.2942\n",
            "Epoch [30060], val_loss: 3878.6287\n",
            "Epoch [30080], val_loss: 3869.1797\n",
            "Epoch [30100], val_loss: 3879.1497\n",
            "Epoch [30120], val_loss: 3873.6921\n",
            "Epoch [30140], val_loss: 3879.4102\n",
            "Epoch [30160], val_loss: 3879.5291\n",
            "Epoch [30180], val_loss: 3869.4578\n",
            "Epoch [30200], val_loss: 3869.3040\n",
            "Epoch [30220], val_loss: 3879.8857\n",
            "Epoch [30240], val_loss: 3870.3621\n",
            "Epoch [30260], val_loss: 3867.5227\n",
            "Epoch [30280], val_loss: 3874.4290\n",
            "Epoch [30300], val_loss: 3883.2468\n",
            "Epoch [30320], val_loss: 3875.5647\n",
            "Epoch [30340], val_loss: 3881.3899\n",
            "Epoch [30360], val_loss: 3876.1907\n",
            "Epoch [30380], val_loss: 3872.9568\n",
            "Epoch [30400], val_loss: 3867.5574\n",
            "Epoch [30420], val_loss: 3877.3762\n",
            "Epoch [30440], val_loss: 3882.7258\n",
            "Epoch [30460], val_loss: 3869.6023\n",
            "Epoch [30480], val_loss: 3869.0215\n",
            "Epoch [30500], val_loss: 3870.1321\n",
            "Epoch [30520], val_loss: 3870.9436\n",
            "Epoch [30540], val_loss: 3871.0293\n",
            "Epoch [30560], val_loss: 3882.4551\n",
            "Epoch [30580], val_loss: 3866.3254\n",
            "Epoch [30600], val_loss: 3876.2859\n",
            "Epoch [30620], val_loss: 3869.5354\n",
            "Epoch [30640], val_loss: 3889.9043\n",
            "Epoch [30660], val_loss: 3884.8494\n",
            "Epoch [30680], val_loss: 3867.7617\n",
            "Epoch [30700], val_loss: 3881.0042\n",
            "Epoch [30720], val_loss: 3870.1667\n",
            "Epoch [30740], val_loss: 3868.8936\n",
            "Epoch [30760], val_loss: 3882.8223\n",
            "Epoch [30780], val_loss: 3870.4192\n",
            "Epoch [30800], val_loss: 3879.8508\n",
            "Epoch [30820], val_loss: 3877.7888\n",
            "Epoch [30840], val_loss: 3874.0156\n",
            "Epoch [30860], val_loss: 3881.2529\n",
            "Epoch [30880], val_loss: 3879.3157\n",
            "Epoch [30900], val_loss: 3870.4160\n",
            "Epoch [30920], val_loss: 3872.4099\n",
            "Epoch [30940], val_loss: 3884.8293\n",
            "Epoch [30960], val_loss: 3883.0889\n",
            "Epoch [30980], val_loss: 3869.7468\n",
            "Epoch [31000], val_loss: 3880.2188\n",
            "Epoch [31020], val_loss: 3872.5515\n",
            "Epoch [31040], val_loss: 3870.8662\n",
            "Epoch [31060], val_loss: 3875.6375\n",
            "Epoch [31080], val_loss: 3873.4299\n",
            "Epoch [31100], val_loss: 3880.3479\n",
            "Epoch [31120], val_loss: 3871.9617\n",
            "Epoch [31140], val_loss: 3872.5500\n",
            "Epoch [31160], val_loss: 3870.9202\n",
            "Epoch [31180], val_loss: 3870.9954\n",
            "Epoch [31200], val_loss: 3884.1199\n",
            "Epoch [31220], val_loss: 3878.4519\n",
            "Epoch [31240], val_loss: 3875.2273\n",
            "Epoch [31260], val_loss: 3875.6750\n",
            "Epoch [31280], val_loss: 3868.7188\n",
            "Epoch [31300], val_loss: 3869.2410\n",
            "Epoch [31320], val_loss: 3872.6042\n",
            "Epoch [31340], val_loss: 3879.7664\n",
            "Epoch [31360], val_loss: 3870.3809\n",
            "Epoch [31380], val_loss: 3872.1292\n",
            "Epoch [31400], val_loss: 3876.6536\n",
            "Epoch [31420], val_loss: 3873.4993\n",
            "Epoch [31440], val_loss: 3870.1299\n",
            "Epoch [31460], val_loss: 3871.8625\n",
            "Epoch [31480], val_loss: 3882.7512\n",
            "Epoch [31500], val_loss: 3882.6223\n",
            "Epoch [31520], val_loss: 3872.6562\n",
            "Epoch [31540], val_loss: 3875.5085\n",
            "Epoch [31560], val_loss: 3875.0955\n",
            "Epoch [31580], val_loss: 3870.6443\n",
            "Epoch [31600], val_loss: 3867.6262\n",
            "Epoch [31620], val_loss: 3875.8945\n",
            "Epoch [31640], val_loss: 3869.5110\n",
            "Epoch [31660], val_loss: 3866.8301\n",
            "Epoch [31680], val_loss: 3866.2610\n",
            "Epoch [31700], val_loss: 3869.1863\n",
            "Epoch [31720], val_loss: 3868.4460\n",
            "Epoch [31740], val_loss: 3873.1877\n",
            "Epoch [31760], val_loss: 3882.9167\n",
            "Epoch [31780], val_loss: 3879.3601\n",
            "Epoch [31800], val_loss: 3867.1687\n",
            "Epoch [31820], val_loss: 3879.2332\n",
            "Epoch [31840], val_loss: 3871.2068\n",
            "Epoch [31860], val_loss: 3871.9570\n",
            "Epoch [31880], val_loss: 3872.3721\n",
            "Epoch [31900], val_loss: 3877.8323\n",
            "Epoch [31920], val_loss: 3881.3518\n",
            "Epoch [31940], val_loss: 3868.9460\n",
            "Epoch [31960], val_loss: 3875.5710\n",
            "Epoch [31980], val_loss: 3876.4277\n",
            "Epoch [32000], val_loss: 3874.7551\n",
            "Epoch [32020], val_loss: 3874.6052\n",
            "Epoch [32040], val_loss: 3895.8997\n",
            "Epoch [32060], val_loss: 3873.6094\n",
            "Epoch [32080], val_loss: 3873.4570\n",
            "Epoch [32100], val_loss: 3878.9929\n",
            "Epoch [32120], val_loss: 3881.9695\n",
            "Epoch [32140], val_loss: 3873.7644\n",
            "Epoch [32160], val_loss: 3870.1172\n",
            "Epoch [32180], val_loss: 3866.3330\n",
            "Epoch [32200], val_loss: 3883.1746\n",
            "Epoch [32220], val_loss: 3882.7754\n",
            "Epoch [32240], val_loss: 3874.1455\n",
            "Epoch [32260], val_loss: 3883.5242\n",
            "Epoch [32280], val_loss: 3870.2500\n",
            "Epoch [32300], val_loss: 3874.1633\n",
            "Epoch [32320], val_loss: 3868.6062\n",
            "Epoch [32340], val_loss: 3869.3162\n",
            "Epoch [32360], val_loss: 3879.9573\n",
            "Epoch [32380], val_loss: 3866.0730\n",
            "Epoch [32400], val_loss: 3875.8894\n",
            "Epoch [32420], val_loss: 3873.5078\n",
            "Epoch [32440], val_loss: 3869.0371\n",
            "Epoch [32460], val_loss: 3883.9617\n",
            "Epoch [32480], val_loss: 3880.6702\n",
            "Epoch [32500], val_loss: 3867.6833\n",
            "Epoch [32520], val_loss: 3887.1604\n",
            "Epoch [32540], val_loss: 3883.7981\n",
            "Epoch [32560], val_loss: 3869.9773\n",
            "Epoch [32580], val_loss: 3883.0793\n",
            "Epoch [32600], val_loss: 3867.3860\n",
            "Epoch [32620], val_loss: 3875.4094\n",
            "Epoch [32640], val_loss: 3870.3779\n",
            "Epoch [32660], val_loss: 3872.0781\n",
            "Epoch [32680], val_loss: 3872.4812\n",
            "Epoch [32700], val_loss: 3871.3416\n",
            "Epoch [32720], val_loss: 3869.6152\n",
            "Epoch [32740], val_loss: 3870.7937\n",
            "Epoch [32760], val_loss: 3864.1133\n",
            "Epoch [32780], val_loss: 3864.9050\n",
            "Epoch [32800], val_loss: 3871.3801\n",
            "Epoch [32820], val_loss: 3868.6121\n",
            "Epoch [32840], val_loss: 3864.4102\n",
            "Epoch [32860], val_loss: 3875.9988\n",
            "Epoch [32880], val_loss: 3867.9924\n",
            "Epoch [32900], val_loss: 3884.9114\n",
            "Epoch [32920], val_loss: 3879.2874\n",
            "Epoch [32940], val_loss: 3867.0232\n",
            "Epoch [32960], val_loss: 3877.4622\n",
            "Epoch [32980], val_loss: 3875.9148\n",
            "Epoch [33000], val_loss: 3869.8477\n",
            "Epoch [33020], val_loss: 3866.7363\n",
            "Epoch [33040], val_loss: 3873.7024\n",
            "Epoch [33060], val_loss: 3869.6770\n",
            "Epoch [33080], val_loss: 3873.4492\n",
            "Epoch [33100], val_loss: 3878.0381\n",
            "Epoch [33120], val_loss: 3876.8757\n",
            "Epoch [33140], val_loss: 3866.3650\n",
            "Epoch [33160], val_loss: 3873.6355\n",
            "Epoch [33180], val_loss: 3872.7024\n",
            "Epoch [33200], val_loss: 3867.4993\n",
            "Epoch [33220], val_loss: 3863.7429\n",
            "Epoch [33240], val_loss: 3874.6687\n",
            "Epoch [33260], val_loss: 3868.9480\n",
            "Epoch [33280], val_loss: 3880.7764\n",
            "Epoch [33300], val_loss: 3879.7263\n",
            "Epoch [33320], val_loss: 3865.9758\n",
            "Epoch [33340], val_loss: 3862.9817\n",
            "Epoch [33360], val_loss: 3869.1741\n",
            "Epoch [33380], val_loss: 3869.0481\n",
            "Epoch [33400], val_loss: 3865.3372\n",
            "Epoch [33420], val_loss: 3866.6184\n",
            "Epoch [33440], val_loss: 3863.9070\n",
            "Epoch [33460], val_loss: 3865.2617\n",
            "Epoch [33480], val_loss: 3872.9102\n",
            "Epoch [33500], val_loss: 3862.6028\n",
            "Epoch [33520], val_loss: 3867.5957\n",
            "Epoch [33540], val_loss: 3864.0051\n",
            "Epoch [33560], val_loss: 3880.4993\n",
            "Epoch [33580], val_loss: 3868.1252\n",
            "Epoch [33600], val_loss: 3867.6926\n",
            "Epoch [33620], val_loss: 3873.8894\n",
            "Epoch [33640], val_loss: 3881.0544\n",
            "Epoch [33660], val_loss: 3871.7493\n",
            "Epoch [33680], val_loss: 3871.5583\n",
            "Epoch [33700], val_loss: 3874.9563\n",
            "Epoch [33720], val_loss: 3877.3743\n",
            "Epoch [33740], val_loss: 3881.6406\n",
            "Epoch [33760], val_loss: 3878.9070\n",
            "Epoch [33780], val_loss: 3875.2024\n",
            "Epoch [33800], val_loss: 3864.7070\n",
            "Epoch [33820], val_loss: 3876.8196\n",
            "Epoch [33840], val_loss: 3866.0950\n",
            "Epoch [33860], val_loss: 3873.7380\n",
            "Epoch [33880], val_loss: 3865.6477\n",
            "Epoch [33900], val_loss: 3865.7129\n",
            "Epoch [33920], val_loss: 3866.4265\n",
            "Epoch [33940], val_loss: 3867.9988\n",
            "Epoch [33960], val_loss: 3868.4851\n",
            "Epoch [33980], val_loss: 3864.0566\n",
            "Epoch [34000], val_loss: 3864.1602\n",
            "Epoch [34020], val_loss: 3866.8118\n",
            "Epoch [34040], val_loss: 3868.3879\n",
            "Epoch [34060], val_loss: 3867.6804\n",
            "Epoch [34080], val_loss: 3874.9080\n",
            "Epoch [34100], val_loss: 3876.8086\n",
            "Epoch [34120], val_loss: 3877.9231\n",
            "Epoch [34140], val_loss: 3877.7258\n",
            "Epoch [34160], val_loss: 3866.4250\n",
            "Epoch [34180], val_loss: 3874.7871\n",
            "Epoch [34200], val_loss: 3876.6418\n",
            "Epoch [34220], val_loss: 3880.7917\n",
            "Epoch [34240], val_loss: 3863.6787\n",
            "Epoch [34260], val_loss: 3863.6055\n",
            "Epoch [34280], val_loss: 3881.5674\n",
            "Epoch [34300], val_loss: 3871.3450\n",
            "Epoch [34320], val_loss: 3882.9294\n",
            "Epoch [34340], val_loss: 3876.8281\n",
            "Epoch [34360], val_loss: 3865.1086\n",
            "Epoch [34380], val_loss: 3876.6133\n",
            "Epoch [34400], val_loss: 3867.3008\n",
            "Epoch [34420], val_loss: 3864.6335\n",
            "Epoch [34440], val_loss: 3873.2441\n",
            "Epoch [34460], val_loss: 3881.2585\n",
            "Epoch [34480], val_loss: 3874.4805\n",
            "Epoch [34500], val_loss: 3871.5769\n",
            "Epoch [34520], val_loss: 3868.2988\n",
            "Epoch [34540], val_loss: 3866.8164\n",
            "Epoch [34560], val_loss: 3863.2869\n",
            "Epoch [34580], val_loss: 3862.5046\n",
            "Epoch [34600], val_loss: 3873.3496\n",
            "Epoch [34620], val_loss: 3865.3796\n",
            "Epoch [34640], val_loss: 3863.2800\n",
            "Epoch [34660], val_loss: 3875.9578\n",
            "Epoch [34680], val_loss: 3863.2986\n",
            "Epoch [34700], val_loss: 3876.4641\n",
            "Epoch [34720], val_loss: 3865.0710\n",
            "Epoch [34740], val_loss: 3866.2859\n",
            "Epoch [34760], val_loss: 3871.4133\n",
            "Epoch [34780], val_loss: 3863.7517\n",
            "Epoch [34800], val_loss: 3868.3203\n",
            "Epoch [34820], val_loss: 3875.4490\n",
            "Epoch [34840], val_loss: 3865.2693\n",
            "Epoch [34860], val_loss: 3871.8176\n",
            "Epoch [34880], val_loss: 3869.2654\n",
            "Epoch [34900], val_loss: 3862.1895\n",
            "Epoch [34920], val_loss: 3867.9463\n",
            "Epoch [34940], val_loss: 3865.4802\n",
            "Epoch [34960], val_loss: 3871.2363\n",
            "Epoch [34980], val_loss: 3870.4055\n",
            "Epoch [35000], val_loss: 3863.7480\n",
            "Epoch [35020], val_loss: 3862.4138\n",
            "Epoch [35040], val_loss: 3864.2117\n",
            "Epoch [35060], val_loss: 3864.5793\n",
            "Epoch [35080], val_loss: 3875.6179\n",
            "Epoch [35100], val_loss: 3869.6914\n",
            "Epoch [35120], val_loss: 3874.5857\n",
            "Epoch [35140], val_loss: 3861.9316\n",
            "Epoch [35160], val_loss: 3866.1047\n",
            "Epoch [35180], val_loss: 3875.0027\n",
            "Epoch [35200], val_loss: 3862.5820\n",
            "Epoch [35220], val_loss: 3866.7688\n",
            "Epoch [35240], val_loss: 3868.3301\n",
            "Epoch [35260], val_loss: 3879.0898\n",
            "Epoch [35280], val_loss: 3866.0559\n",
            "Epoch [35300], val_loss: 3866.6140\n",
            "Epoch [35320], val_loss: 3874.0293\n",
            "Epoch [35340], val_loss: 3865.3828\n",
            "Epoch [35360], val_loss: 3869.1719\n",
            "Epoch [35380], val_loss: 3860.7507\n",
            "Epoch [35400], val_loss: 3864.2278\n",
            "Epoch [35420], val_loss: 3866.9578\n",
            "Epoch [35440], val_loss: 3866.2170\n",
            "Epoch [35460], val_loss: 3873.0740\n",
            "Epoch [35480], val_loss: 3867.9883\n",
            "Epoch [35500], val_loss: 3867.1687\n",
            "Epoch [35520], val_loss: 3862.2764\n",
            "Epoch [35540], val_loss: 3878.7637\n",
            "Epoch [35560], val_loss: 3874.2090\n",
            "Epoch [35580], val_loss: 3866.1531\n",
            "Epoch [35600], val_loss: 3871.6836\n",
            "Epoch [35620], val_loss: 3879.4666\n",
            "Epoch [35640], val_loss: 3861.2083\n",
            "Epoch [35660], val_loss: 3864.5081\n",
            "Epoch [35680], val_loss: 3871.2371\n",
            "Epoch [35700], val_loss: 3873.4148\n",
            "Epoch [35720], val_loss: 3871.6765\n",
            "Epoch [35740], val_loss: 3866.3079\n",
            "Epoch [35760], val_loss: 3866.6035\n",
            "Epoch [35780], val_loss: 3860.6985\n",
            "Epoch [35800], val_loss: 3865.1230\n",
            "Epoch [35820], val_loss: 3868.6660\n",
            "Epoch [35840], val_loss: 3877.5801\n",
            "Epoch [35860], val_loss: 3865.2383\n",
            "Epoch [35880], val_loss: 3877.5742\n",
            "Epoch [35900], val_loss: 3867.8132\n",
            "Epoch [35920], val_loss: 3870.7676\n",
            "Epoch [35940], val_loss: 3868.8826\n",
            "Epoch [35960], val_loss: 3869.6316\n",
            "Epoch [35980], val_loss: 3866.0820\n",
            "Epoch [36000], val_loss: 3865.1641\n",
            "Epoch [36020], val_loss: 3872.2468\n",
            "Epoch [36040], val_loss: 3868.5066\n",
            "Epoch [36060], val_loss: 3861.6045\n",
            "Epoch [36080], val_loss: 3860.2188\n",
            "Epoch [36100], val_loss: 3860.6692\n",
            "Epoch [36120], val_loss: 3871.8103\n",
            "Epoch [36140], val_loss: 3866.5129\n",
            "Epoch [36160], val_loss: 3862.7761\n",
            "Epoch [36180], val_loss: 3866.3879\n",
            "Epoch [36200], val_loss: 3875.4385\n",
            "Epoch [36220], val_loss: 3866.8054\n",
            "Epoch [36240], val_loss: 3863.8174\n",
            "Epoch [36260], val_loss: 3861.8125\n",
            "Epoch [36280], val_loss: 3865.0256\n",
            "Epoch [36300], val_loss: 3861.1814\n",
            "Epoch [36320], val_loss: 3864.4343\n",
            "Epoch [36340], val_loss: 3873.2949\n",
            "Epoch [36360], val_loss: 3878.7429\n",
            "Epoch [36380], val_loss: 3863.4016\n",
            "Epoch [36400], val_loss: 3867.9187\n",
            "Epoch [36420], val_loss: 3864.5500\n",
            "Epoch [36440], val_loss: 3866.0938\n",
            "Epoch [36460], val_loss: 3865.4336\n",
            "Epoch [36480], val_loss: 3867.7063\n",
            "Epoch [36500], val_loss: 3873.2957\n",
            "Epoch [36520], val_loss: 3871.9062\n",
            "Epoch [36540], val_loss: 3871.1189\n",
            "Epoch [36560], val_loss: 3881.2644\n",
            "Epoch [36580], val_loss: 3865.9617\n",
            "Epoch [36600], val_loss: 3884.8506\n",
            "Epoch [36620], val_loss: 3862.2871\n",
            "Epoch [36640], val_loss: 3873.6270\n",
            "Epoch [36660], val_loss: 3868.0339\n",
            "Epoch [36680], val_loss: 3863.7734\n",
            "Epoch [36700], val_loss: 3870.4316\n",
            "Epoch [36720], val_loss: 3868.9265\n",
            "Epoch [36740], val_loss: 3864.2209\n",
            "Epoch [36760], val_loss: 3865.0886\n",
            "Epoch [36780], val_loss: 3878.4421\n",
            "Epoch [36800], val_loss: 3863.9363\n",
            "Epoch [36820], val_loss: 3872.7019\n",
            "Epoch [36840], val_loss: 3863.9539\n",
            "Epoch [36860], val_loss: 3864.0381\n",
            "Epoch [36880], val_loss: 3860.9250\n",
            "Epoch [36900], val_loss: 3859.3047\n",
            "Epoch [36920], val_loss: 3865.0969\n",
            "Epoch [36940], val_loss: 3861.2102\n",
            "Epoch [36960], val_loss: 3869.8621\n",
            "Epoch [36980], val_loss: 3866.9656\n",
            "Epoch [37000], val_loss: 3873.7273\n",
            "Epoch [37020], val_loss: 3879.4641\n",
            "Epoch [37040], val_loss: 3861.6326\n",
            "Epoch [37060], val_loss: 3861.7517\n",
            "Epoch [37080], val_loss: 3870.1541\n",
            "Epoch [37100], val_loss: 3869.4727\n",
            "Epoch [37120], val_loss: 3861.2051\n",
            "Epoch [37140], val_loss: 3868.9231\n",
            "Epoch [37160], val_loss: 3867.1211\n",
            "Epoch [37180], val_loss: 3879.7952\n",
            "Epoch [37200], val_loss: 3872.4094\n",
            "Epoch [37220], val_loss: 3859.4636\n",
            "Epoch [37240], val_loss: 3873.3762\n",
            "Epoch [37260], val_loss: 3875.6243\n",
            "Epoch [37280], val_loss: 3870.7344\n",
            "Epoch [37300], val_loss: 3869.3743\n",
            "Epoch [37320], val_loss: 3866.2666\n",
            "Epoch [37340], val_loss: 3867.9434\n",
            "Epoch [37360], val_loss: 3869.9307\n",
            "Epoch [37380], val_loss: 3864.3235\n",
            "Epoch [37400], val_loss: 3863.4453\n",
            "Epoch [37420], val_loss: 3881.2146\n",
            "Epoch [37440], val_loss: 3877.3757\n",
            "Epoch [37460], val_loss: 3864.4912\n",
            "Epoch [37480], val_loss: 3866.3875\n",
            "Epoch [37500], val_loss: 3860.3425\n",
            "Epoch [37520], val_loss: 3866.2712\n",
            "Epoch [37540], val_loss: 3869.9421\n",
            "Epoch [37560], val_loss: 3859.3396\n",
            "Epoch [37580], val_loss: 3868.8362\n",
            "Epoch [37600], val_loss: 3879.4138\n",
            "Epoch [37620], val_loss: 3868.3879\n",
            "Epoch [37640], val_loss: 3867.1162\n",
            "Epoch [37660], val_loss: 3869.1868\n",
            "Epoch [37680], val_loss: 3868.2207\n",
            "Epoch [37700], val_loss: 3866.3184\n",
            "Epoch [37720], val_loss: 3869.5618\n",
            "Epoch [37740], val_loss: 3863.1228\n",
            "Epoch [37760], val_loss: 3863.7996\n",
            "Epoch [37780], val_loss: 3862.5703\n",
            "Epoch [37800], val_loss: 3861.2590\n",
            "Epoch [37820], val_loss: 3857.7783\n",
            "Epoch [37840], val_loss: 3866.4075\n",
            "Epoch [37860], val_loss: 3859.2688\n",
            "Epoch [37880], val_loss: 3868.0071\n",
            "Epoch [37900], val_loss: 3866.6199\n",
            "Epoch [37920], val_loss: 3859.7305\n",
            "Epoch [37940], val_loss: 3867.9980\n",
            "Epoch [37960], val_loss: 3865.8171\n",
            "Epoch [37980], val_loss: 3869.7549\n",
            "Epoch [38000], val_loss: 3861.6309\n",
            "Epoch [38020], val_loss: 3865.6707\n",
            "Epoch [38040], val_loss: 3866.1770\n",
            "Epoch [38060], val_loss: 3858.6165\n",
            "Epoch [38080], val_loss: 3881.9915\n",
            "Epoch [38100], val_loss: 3859.9980\n",
            "Epoch [38120], val_loss: 3860.5762\n",
            "Epoch [38140], val_loss: 3869.1191\n",
            "Epoch [38160], val_loss: 3873.6741\n",
            "Epoch [38180], val_loss: 3863.0125\n",
            "Epoch [38200], val_loss: 3873.7793\n",
            "Epoch [38220], val_loss: 3862.4539\n",
            "Epoch [38240], val_loss: 3858.6501\n",
            "Epoch [38260], val_loss: 3858.9275\n",
            "Epoch [38280], val_loss: 3867.5012\n",
            "Epoch [38300], val_loss: 3881.2195\n",
            "Epoch [38320], val_loss: 3863.5352\n",
            "Epoch [38340], val_loss: 3863.3059\n",
            "Epoch [38360], val_loss: 3863.2783\n",
            "Epoch [38380], val_loss: 3866.1101\n",
            "Epoch [38400], val_loss: 3863.5264\n",
            "Epoch [38420], val_loss: 3874.2898\n",
            "Epoch [38440], val_loss: 3859.2844\n",
            "Epoch [38460], val_loss: 3864.5515\n",
            "Epoch [38480], val_loss: 3872.8528\n",
            "Epoch [38500], val_loss: 3872.1230\n",
            "Epoch [38520], val_loss: 3862.5520\n",
            "Epoch [38540], val_loss: 3860.6975\n",
            "Epoch [38560], val_loss: 3863.4988\n",
            "Epoch [38580], val_loss: 3864.6653\n",
            "Epoch [38600], val_loss: 3872.8044\n",
            "Epoch [38620], val_loss: 3859.0723\n",
            "Epoch [38640], val_loss: 3871.0918\n",
            "Epoch [38660], val_loss: 3863.5654\n",
            "Epoch [38680], val_loss: 3865.5911\n",
            "Epoch [38700], val_loss: 3856.8308\n",
            "Epoch [38720], val_loss: 3858.4111\n",
            "Epoch [38740], val_loss: 3864.0188\n",
            "Epoch [38760], val_loss: 3868.8184\n",
            "Epoch [38780], val_loss: 3859.2976\n",
            "Epoch [38800], val_loss: 3862.5488\n",
            "Epoch [38820], val_loss: 3861.8000\n",
            "Epoch [38840], val_loss: 3871.0945\n",
            "Epoch [38860], val_loss: 3859.7734\n",
            "Epoch [38880], val_loss: 3868.7629\n",
            "Epoch [38900], val_loss: 3863.9785\n",
            "Epoch [38920], val_loss: 3861.8713\n",
            "Epoch [38940], val_loss: 3861.4758\n",
            "Epoch [38960], val_loss: 3868.4062\n",
            "Epoch [38980], val_loss: 3861.5476\n",
            "Epoch [39000], val_loss: 3860.9519\n",
            "Epoch [39020], val_loss: 3864.2083\n",
            "Epoch [39040], val_loss: 3864.2188\n",
            "Epoch [39060], val_loss: 3870.7444\n",
            "Epoch [39080], val_loss: 3862.2810\n",
            "Epoch [39100], val_loss: 3863.4402\n",
            "Epoch [39120], val_loss: 3864.9072\n",
            "Epoch [39140], val_loss: 3863.4043\n",
            "Epoch [39160], val_loss: 3868.4934\n",
            "Epoch [39180], val_loss: 3859.7949\n",
            "Epoch [39200], val_loss: 3868.0984\n",
            "Epoch [39220], val_loss: 3861.6394\n",
            "Epoch [39240], val_loss: 3857.3076\n",
            "Epoch [39260], val_loss: 3856.8066\n",
            "Epoch [39280], val_loss: 3860.2292\n",
            "Epoch [39300], val_loss: 3857.8250\n",
            "Epoch [39320], val_loss: 3861.8689\n",
            "Epoch [39340], val_loss: 3867.5637\n",
            "Epoch [39360], val_loss: 3862.4805\n",
            "Epoch [39380], val_loss: 3864.4226\n",
            "Epoch [39400], val_loss: 3865.4355\n",
            "Epoch [39420], val_loss: 3865.7786\n",
            "Epoch [39440], val_loss: 3860.7383\n",
            "Epoch [39460], val_loss: 3861.3391\n",
            "Epoch [39480], val_loss: 3868.5339\n",
            "Epoch [39500], val_loss: 3857.4412\n",
            "Epoch [39520], val_loss: 3871.1133\n",
            "Epoch [39540], val_loss: 3871.0537\n",
            "Epoch [39560], val_loss: 3871.8992\n",
            "Epoch [39580], val_loss: 3861.5320\n",
            "Epoch [39600], val_loss: 3868.1887\n",
            "Epoch [39620], val_loss: 3864.8796\n",
            "Epoch [39640], val_loss: 3863.6838\n",
            "Epoch [39660], val_loss: 3860.4238\n",
            "Epoch [39680], val_loss: 3869.0957\n",
            "Epoch [39700], val_loss: 3860.5701\n",
            "Epoch [39720], val_loss: 3866.8047\n",
            "Epoch [39740], val_loss: 3861.8523\n",
            "Epoch [39760], val_loss: 3860.7363\n",
            "Epoch [39780], val_loss: 3859.4387\n",
            "Epoch [39800], val_loss: 3869.5793\n",
            "Epoch [39820], val_loss: 3855.3547\n",
            "Epoch [39840], val_loss: 3857.7695\n",
            "Epoch [39860], val_loss: 3863.7532\n",
            "Epoch [39880], val_loss: 3868.1204\n",
            "Epoch [39900], val_loss: 3856.5808\n",
            "Epoch [39920], val_loss: 3876.3809\n",
            "Epoch [39940], val_loss: 3862.8147\n",
            "Epoch [39960], val_loss: 3856.0410\n",
            "Epoch [39980], val_loss: 3877.8972\n",
            "Epoch [40000], val_loss: 3856.3210\n",
            "Epoch [40020], val_loss: 3867.0996\n",
            "Epoch [40040], val_loss: 3872.7773\n",
            "Epoch [40060], val_loss: 3861.7273\n",
            "Epoch [40080], val_loss: 3876.2078\n",
            "Epoch [40100], val_loss: 3871.6707\n",
            "Epoch [40120], val_loss: 3869.4658\n",
            "Epoch [40140], val_loss: 3859.2351\n",
            "Epoch [40160], val_loss: 3862.4375\n",
            "Epoch [40180], val_loss: 3866.3457\n",
            "Epoch [40200], val_loss: 3862.1016\n",
            "Epoch [40220], val_loss: 3867.0984\n",
            "Epoch [40240], val_loss: 3859.5479\n",
            "Epoch [40260], val_loss: 3858.3145\n",
            "Epoch [40280], val_loss: 3865.6367\n",
            "Epoch [40300], val_loss: 3869.7683\n",
            "Epoch [40320], val_loss: 3856.1545\n",
            "Epoch [40340], val_loss: 3865.0615\n",
            "Epoch [40360], val_loss: 3868.6504\n",
            "Epoch [40380], val_loss: 3859.5332\n",
            "Epoch [40400], val_loss: 3864.4172\n",
            "Epoch [40420], val_loss: 3862.4697\n",
            "Epoch [40440], val_loss: 3866.0117\n",
            "Epoch [40460], val_loss: 3859.1169\n",
            "Epoch [40480], val_loss: 3865.9485\n",
            "Epoch [40500], val_loss: 3865.1189\n",
            "Epoch [40520], val_loss: 3866.8391\n",
            "Epoch [40540], val_loss: 3872.9109\n",
            "Epoch [40560], val_loss: 3860.4131\n",
            "Epoch [40580], val_loss: 3863.0027\n",
            "Epoch [40600], val_loss: 3857.6375\n",
            "Epoch [40620], val_loss: 3858.1465\n",
            "Epoch [40640], val_loss: 3863.3777\n",
            "Epoch [40660], val_loss: 3861.9871\n",
            "Epoch [40680], val_loss: 3859.8347\n",
            "Epoch [40700], val_loss: 3856.3894\n",
            "Epoch [40720], val_loss: 3862.3086\n",
            "Epoch [40740], val_loss: 3856.5234\n",
            "Epoch [40760], val_loss: 3853.8411\n",
            "Epoch [40780], val_loss: 3857.3875\n",
            "Epoch [40800], val_loss: 3862.6418\n",
            "Epoch [40820], val_loss: 3867.0696\n",
            "Epoch [40840], val_loss: 3864.9504\n",
            "Epoch [40860], val_loss: 3855.6445\n",
            "Epoch [40880], val_loss: 3865.3420\n",
            "Epoch [40900], val_loss: 3873.5066\n",
            "Epoch [40920], val_loss: 3860.8010\n",
            "Epoch [40940], val_loss: 3861.1399\n",
            "Epoch [40960], val_loss: 3867.4714\n",
            "Epoch [40980], val_loss: 3855.6787\n",
            "Epoch [41000], val_loss: 3857.2610\n",
            "Epoch [41020], val_loss: 3857.6445\n",
            "Epoch [41040], val_loss: 3855.4548\n",
            "Epoch [41060], val_loss: 3875.1082\n",
            "Epoch [41080], val_loss: 3865.1516\n",
            "Epoch [41100], val_loss: 3862.6843\n",
            "Epoch [41120], val_loss: 3867.0183\n",
            "Epoch [41140], val_loss: 3865.4382\n",
            "Epoch [41160], val_loss: 3861.8997\n",
            "Epoch [41180], val_loss: 3876.0662\n",
            "Epoch [41200], val_loss: 3860.4890\n",
            "Epoch [41220], val_loss: 3867.4631\n",
            "Epoch [41240], val_loss: 3857.2920\n",
            "Epoch [41260], val_loss: 3859.7356\n",
            "Epoch [41280], val_loss: 3853.9050\n",
            "Epoch [41300], val_loss: 3860.5286\n",
            "Epoch [41320], val_loss: 3861.8083\n",
            "Epoch [41340], val_loss: 3869.4880\n",
            "Epoch [41360], val_loss: 3860.5686\n",
            "Epoch [41380], val_loss: 3860.5598\n",
            "Epoch [41400], val_loss: 3866.2595\n",
            "Epoch [41420], val_loss: 3854.1013\n",
            "Epoch [41440], val_loss: 3862.4697\n",
            "Epoch [41460], val_loss: 3859.1648\n",
            "Epoch [41480], val_loss: 3856.0305\n",
            "Epoch [41500], val_loss: 3855.7141\n",
            "Epoch [41520], val_loss: 3855.1204\n",
            "Epoch [41540], val_loss: 3856.6643\n",
            "Epoch [41560], val_loss: 3864.3633\n",
            "Epoch [41580], val_loss: 3857.3796\n",
            "Epoch [41600], val_loss: 3869.7324\n",
            "Epoch [41620], val_loss: 3859.5515\n",
            "Epoch [41640], val_loss: 3867.6035\n",
            "Epoch [41660], val_loss: 3869.4875\n",
            "Epoch [41680], val_loss: 3862.0154\n",
            "Epoch [41700], val_loss: 3872.8010\n",
            "Epoch [41720], val_loss: 3864.5071\n",
            "Epoch [41740], val_loss: 3863.2686\n",
            "Epoch [41760], val_loss: 3861.1453\n",
            "Epoch [41780], val_loss: 3861.3333\n",
            "Epoch [41800], val_loss: 3857.4460\n",
            "Epoch [41820], val_loss: 3868.3025\n",
            "Epoch [41840], val_loss: 3858.6758\n",
            "Epoch [41860], val_loss: 3853.2031\n",
            "Epoch [41880], val_loss: 3873.4128\n",
            "Epoch [41900], val_loss: 3859.5078\n",
            "Epoch [41920], val_loss: 3856.6423\n",
            "Epoch [41940], val_loss: 3868.9695\n",
            "Epoch [41960], val_loss: 3858.9294\n",
            "Epoch [41980], val_loss: 3865.3796\n",
            "Epoch [42000], val_loss: 3870.5713\n",
            "Epoch [42020], val_loss: 3868.0925\n",
            "Epoch [42040], val_loss: 3856.4094\n",
            "Epoch [42060], val_loss: 3860.9473\n",
            "Epoch [42080], val_loss: 3861.9062\n",
            "Epoch [42100], val_loss: 3865.2004\n",
            "Epoch [42120], val_loss: 3866.1584\n",
            "Epoch [42140], val_loss: 3859.5295\n",
            "Epoch [42160], val_loss: 3863.9011\n",
            "Epoch [42180], val_loss: 3869.3118\n",
            "Epoch [42200], val_loss: 3863.7000\n",
            "Epoch [42220], val_loss: 3869.2224\n",
            "Epoch [42240], val_loss: 3860.3953\n",
            "Epoch [42260], val_loss: 3867.7517\n",
            "Epoch [42280], val_loss: 3861.7625\n",
            "Epoch [42300], val_loss: 3855.1045\n",
            "Epoch [42320], val_loss: 3866.5479\n",
            "Epoch [42340], val_loss: 3860.6458\n",
            "Epoch [42360], val_loss: 3877.3772\n",
            "Epoch [42380], val_loss: 3864.0261\n",
            "Epoch [42400], val_loss: 3858.7852\n",
            "Epoch [42420], val_loss: 3874.9949\n",
            "Epoch [42440], val_loss: 3855.7188\n",
            "Epoch [42460], val_loss: 3862.9700\n",
            "Epoch [42480], val_loss: 3863.8789\n",
            "Epoch [42500], val_loss: 3862.1218\n",
            "Epoch [42520], val_loss: 3856.2297\n",
            "Epoch [42540], val_loss: 3880.8484\n",
            "Epoch [42560], val_loss: 3866.2629\n",
            "Epoch [42580], val_loss: 3860.8379\n",
            "Epoch [42600], val_loss: 3854.8904\n",
            "Epoch [42620], val_loss: 3860.1296\n",
            "Epoch [42640], val_loss: 3852.8621\n",
            "Epoch [42660], val_loss: 3862.5105\n",
            "Epoch [42680], val_loss: 3857.6892\n",
            "Epoch [42700], val_loss: 3861.1355\n",
            "Epoch [42720], val_loss: 3862.3562\n",
            "Epoch [42740], val_loss: 3864.5334\n",
            "Epoch [42760], val_loss: 3860.7317\n",
            "Epoch [42780], val_loss: 3853.3420\n",
            "Epoch [42800], val_loss: 3876.2551\n",
            "Epoch [42820], val_loss: 3855.3147\n",
            "Epoch [42840], val_loss: 3859.3066\n",
            "Epoch [42860], val_loss: 3867.5671\n",
            "Epoch [42880], val_loss: 3858.9932\n",
            "Epoch [42900], val_loss: 3863.0420\n",
            "Epoch [42920], val_loss: 3866.6179\n",
            "Epoch [42940], val_loss: 3880.7832\n",
            "Epoch [42960], val_loss: 3856.7275\n",
            "Epoch [42980], val_loss: 3871.7395\n",
            "Epoch [43000], val_loss: 3854.8066\n",
            "Epoch [43020], val_loss: 3857.6770\n",
            "Epoch [43040], val_loss: 3860.9675\n",
            "Epoch [43060], val_loss: 3864.9143\n",
            "Epoch [43080], val_loss: 3876.6140\n",
            "Epoch [43100], val_loss: 3860.5840\n",
            "Epoch [43120], val_loss: 3860.2324\n",
            "Epoch [43140], val_loss: 3860.5808\n",
            "Epoch [43160], val_loss: 3859.4688\n",
            "Epoch [43180], val_loss: 3867.1973\n",
            "Epoch [43200], val_loss: 3859.1672\n",
            "Epoch [43220], val_loss: 3861.8738\n",
            "Epoch [43240], val_loss: 3861.8855\n",
            "Epoch [43260], val_loss: 3858.6355\n",
            "Epoch [43280], val_loss: 3859.9980\n",
            "Epoch [43300], val_loss: 3867.1921\n",
            "Epoch [43320], val_loss: 3867.5750\n",
            "Epoch [43340], val_loss: 3860.7891\n",
            "Epoch [43360], val_loss: 3866.1951\n",
            "Epoch [43380], val_loss: 3870.1016\n",
            "Epoch [43400], val_loss: 3855.3577\n",
            "Epoch [43420], val_loss: 3874.5559\n",
            "Epoch [43440], val_loss: 3864.3171\n",
            "Epoch [43460], val_loss: 3860.4446\n",
            "Epoch [43480], val_loss: 3866.2324\n",
            "Epoch [43500], val_loss: 3866.9602\n",
            "Epoch [43520], val_loss: 3861.3176\n",
            "Epoch [43540], val_loss: 3863.6667\n",
            "Epoch [43560], val_loss: 3863.2454\n",
            "Epoch [43580], val_loss: 3865.9873\n",
            "Epoch [43600], val_loss: 3857.5957\n",
            "Epoch [43620], val_loss: 3851.7429\n",
            "Epoch [43640], val_loss: 3865.3850\n",
            "Epoch [43660], val_loss: 3858.4753\n",
            "Epoch [43680], val_loss: 3852.7891\n",
            "Epoch [43700], val_loss: 3862.8225\n",
            "Epoch [43720], val_loss: 3866.6133\n",
            "Epoch [43740], val_loss: 3856.7043\n",
            "Epoch [43760], val_loss: 3854.1523\n",
            "Epoch [43780], val_loss: 3854.5547\n",
            "Epoch [43800], val_loss: 3867.0247\n",
            "Epoch [43820], val_loss: 3851.9036\n",
            "Epoch [43840], val_loss: 3864.5974\n",
            "Epoch [43860], val_loss: 3862.4617\n",
            "Epoch [43880], val_loss: 3862.8401\n",
            "Epoch [43900], val_loss: 3856.1270\n",
            "Epoch [43920], val_loss: 3857.5576\n",
            "Epoch [43940], val_loss: 3857.5925\n",
            "Epoch [43960], val_loss: 3861.7969\n",
            "Epoch [43980], val_loss: 3858.5632\n",
            "Epoch [44000], val_loss: 3856.5557\n",
            "Epoch [44020], val_loss: 3873.5071\n",
            "Epoch [44040], val_loss: 3856.8933\n",
            "Epoch [44060], val_loss: 3866.1716\n",
            "Epoch [44080], val_loss: 3858.9133\n",
            "Epoch [44100], val_loss: 3853.4375\n",
            "Epoch [44120], val_loss: 3859.6321\n",
            "Epoch [44140], val_loss: 3856.3997\n",
            "Epoch [44160], val_loss: 3850.3606\n",
            "Epoch [44180], val_loss: 3857.2590\n",
            "Epoch [44200], val_loss: 3866.2334\n",
            "Epoch [44220], val_loss: 3857.6042\n",
            "Epoch [44240], val_loss: 3861.2305\n",
            "Epoch [44260], val_loss: 3854.7227\n",
            "Epoch [44280], val_loss: 3860.2441\n",
            "Epoch [44300], val_loss: 3862.2297\n",
            "Epoch [44320], val_loss: 3856.2617\n",
            "Epoch [44340], val_loss: 3850.8367\n",
            "Epoch [44360], val_loss: 3857.1375\n",
            "Epoch [44380], val_loss: 3861.2004\n",
            "Epoch [44400], val_loss: 3861.3210\n",
            "Epoch [44420], val_loss: 3869.6484\n",
            "Epoch [44440], val_loss: 3873.3860\n",
            "Epoch [44460], val_loss: 3851.5403\n",
            "Epoch [44480], val_loss: 3850.8357\n",
            "Epoch [44500], val_loss: 3855.0029\n",
            "Epoch [44520], val_loss: 3856.9915\n",
            "Epoch [44540], val_loss: 3864.6807\n",
            "Epoch [44560], val_loss: 3855.7012\n",
            "Epoch [44580], val_loss: 3854.1250\n",
            "Epoch [44600], val_loss: 3861.8164\n",
            "Epoch [44620], val_loss: 3852.8711\n",
            "Epoch [44640], val_loss: 3854.5691\n",
            "Epoch [44660], val_loss: 3867.9033\n",
            "Epoch [44680], val_loss: 3868.0461\n",
            "Epoch [44700], val_loss: 3854.6331\n",
            "Epoch [44720], val_loss: 3856.9949\n",
            "Epoch [44740], val_loss: 3863.0520\n",
            "Epoch [44760], val_loss: 3863.0388\n",
            "Epoch [44780], val_loss: 3852.9746\n",
            "Epoch [44800], val_loss: 3857.8816\n",
            "Epoch [44820], val_loss: 3857.2410\n",
            "Epoch [44840], val_loss: 3855.6934\n",
            "Epoch [44860], val_loss: 3856.6536\n",
            "Epoch [44880], val_loss: 3856.0520\n",
            "Epoch [44900], val_loss: 3855.0754\n",
            "Epoch [44920], val_loss: 3855.9109\n",
            "Epoch [44940], val_loss: 3877.6570\n",
            "Epoch [44960], val_loss: 3854.5857\n",
            "Epoch [44980], val_loss: 3865.3086\n",
            "Epoch [45000], val_loss: 3864.4668\n",
            "Epoch [45020], val_loss: 3856.6414\n",
            "Epoch [45040], val_loss: 3861.9446\n",
            "Epoch [45060], val_loss: 3858.0208\n",
            "Epoch [45080], val_loss: 3853.6738\n",
            "Epoch [45100], val_loss: 3854.4910\n",
            "Epoch [45120], val_loss: 3860.8469\n",
            "Epoch [45140], val_loss: 3865.0735\n",
            "Epoch [45160], val_loss: 3856.8049\n",
            "Epoch [45180], val_loss: 3851.9597\n",
            "Epoch [45200], val_loss: 3862.1956\n",
            "Epoch [45220], val_loss: 3854.1296\n",
            "Epoch [45240], val_loss: 3872.5964\n",
            "Epoch [45260], val_loss: 3859.6887\n",
            "Epoch [45280], val_loss: 3855.6521\n",
            "Epoch [45300], val_loss: 3853.8184\n",
            "Epoch [45320], val_loss: 3861.1172\n",
            "Epoch [45340], val_loss: 3862.4014\n",
            "Epoch [45360], val_loss: 3855.1125\n",
            "Epoch [45380], val_loss: 3858.7253\n",
            "Epoch [45400], val_loss: 3864.0554\n",
            "Epoch [45420], val_loss: 3861.3047\n",
            "Epoch [45440], val_loss: 3862.6707\n",
            "Epoch [45460], val_loss: 3855.1780\n",
            "Epoch [45480], val_loss: 3853.2122\n",
            "Epoch [45500], val_loss: 3854.6184\n",
            "Epoch [45520], val_loss: 3862.7874\n",
            "Epoch [45540], val_loss: 3853.7004\n",
            "Epoch [45560], val_loss: 3857.3806\n",
            "Epoch [45580], val_loss: 3853.5291\n",
            "Epoch [45600], val_loss: 3853.7385\n",
            "Epoch [45620], val_loss: 3859.8152\n",
            "Epoch [45640], val_loss: 3857.0593\n",
            "Epoch [45660], val_loss: 3856.6199\n",
            "Epoch [45680], val_loss: 3853.3723\n",
            "Epoch [45700], val_loss: 3867.1101\n",
            "Epoch [45720], val_loss: 3864.5891\n",
            "Epoch [45740], val_loss: 3864.0891\n",
            "Epoch [45760], val_loss: 3859.1384\n",
            "Epoch [45780], val_loss: 3849.5989\n",
            "Epoch [45800], val_loss: 3854.4231\n",
            "Epoch [45820], val_loss: 3859.2117\n",
            "Epoch [45840], val_loss: 3851.5935\n",
            "Epoch [45860], val_loss: 3856.2354\n",
            "Epoch [45880], val_loss: 3865.3020\n",
            "Epoch [45900], val_loss: 3857.3308\n",
            "Epoch [45920], val_loss: 3862.1672\n",
            "Epoch [45940], val_loss: 3860.9363\n",
            "Epoch [45960], val_loss: 3854.4941\n",
            "Epoch [45980], val_loss: 3864.2090\n",
            "Epoch [46000], val_loss: 3854.9365\n",
            "Epoch [46020], val_loss: 3853.2971\n",
            "Epoch [46040], val_loss: 3866.3669\n",
            "Epoch [46060], val_loss: 3857.9802\n",
            "Epoch [46080], val_loss: 3860.7649\n",
            "Epoch [46100], val_loss: 3855.0793\n",
            "Epoch [46120], val_loss: 3857.9929\n",
            "Epoch [46140], val_loss: 3857.5032\n",
            "Epoch [46160], val_loss: 3857.3523\n",
            "Epoch [46180], val_loss: 3862.1287\n",
            "Epoch [46200], val_loss: 3851.9192\n",
            "Epoch [46220], val_loss: 3854.7024\n",
            "Epoch [46240], val_loss: 3866.2542\n",
            "Epoch [46260], val_loss: 3860.9182\n",
            "Epoch [46280], val_loss: 3854.1492\n",
            "Epoch [46300], val_loss: 3855.9043\n",
            "Epoch [46320], val_loss: 3856.7283\n",
            "Epoch [46340], val_loss: 3853.2673\n",
            "Epoch [46360], val_loss: 3858.1504\n",
            "Epoch [46380], val_loss: 3855.2571\n",
            "Epoch [46400], val_loss: 3858.1301\n",
            "Epoch [46420], val_loss: 3860.5146\n",
            "Epoch [46440], val_loss: 3864.0813\n",
            "Epoch [46460], val_loss: 3859.3789\n",
            "Epoch [46480], val_loss: 3864.6223\n",
            "Epoch [46500], val_loss: 3855.3320\n",
            "Epoch [46520], val_loss: 3857.3704\n",
            "Epoch [46540], val_loss: 3859.6809\n",
            "Epoch [46560], val_loss: 3851.5352\n",
            "Epoch [46580], val_loss: 3862.8743\n",
            "Epoch [46600], val_loss: 3865.9365\n",
            "Epoch [46620], val_loss: 3859.8738\n",
            "Epoch [46640], val_loss: 3853.8167\n",
            "Epoch [46660], val_loss: 3858.7136\n",
            "Epoch [46680], val_loss: 3869.0208\n",
            "Epoch [46700], val_loss: 3852.0056\n",
            "Epoch [46720], val_loss: 3871.8457\n",
            "Epoch [46740], val_loss: 3853.8977\n",
            "Epoch [46760], val_loss: 3861.4373\n",
            "Epoch [46780], val_loss: 3858.0935\n",
            "Epoch [46800], val_loss: 3853.1272\n",
            "Epoch [46820], val_loss: 3854.7278\n",
            "Epoch [46840], val_loss: 3861.7883\n",
            "Epoch [46860], val_loss: 3857.2703\n",
            "Epoch [46880], val_loss: 3849.3757\n",
            "Epoch [46900], val_loss: 3861.3933\n",
            "Epoch [46920], val_loss: 3871.3408\n",
            "Epoch [46940], val_loss: 3848.4265\n",
            "Epoch [46960], val_loss: 3856.2139\n",
            "Epoch [46980], val_loss: 3857.9724\n",
            "Epoch [47000], val_loss: 3857.3125\n",
            "Epoch [47020], val_loss: 3863.3762\n",
            "Epoch [47040], val_loss: 3856.8347\n",
            "Epoch [47060], val_loss: 3851.7786\n",
            "Epoch [47080], val_loss: 3864.3137\n",
            "Epoch [47100], val_loss: 3860.9426\n",
            "Epoch [47120], val_loss: 3852.2727\n",
            "Epoch [47140], val_loss: 3857.7451\n",
            "Epoch [47160], val_loss: 3861.3525\n",
            "Epoch [47180], val_loss: 3854.6406\n",
            "Epoch [47200], val_loss: 3855.9138\n",
            "Epoch [47220], val_loss: 3856.1660\n",
            "Epoch [47240], val_loss: 3861.3015\n",
            "Epoch [47260], val_loss: 3852.5547\n",
            "Epoch [47280], val_loss: 3863.6277\n",
            "Epoch [47300], val_loss: 3862.6160\n",
            "Epoch [47320], val_loss: 3866.8601\n",
            "Epoch [47340], val_loss: 3867.1414\n",
            "Epoch [47360], val_loss: 3865.6536\n",
            "Epoch [47380], val_loss: 3854.1746\n",
            "Epoch [47400], val_loss: 3850.9453\n",
            "Epoch [47420], val_loss: 3859.8137\n",
            "Epoch [47440], val_loss: 3862.5586\n",
            "Epoch [47460], val_loss: 3848.3333\n",
            "Epoch [47480], val_loss: 3865.7803\n",
            "Epoch [47500], val_loss: 3856.5813\n",
            "Epoch [47520], val_loss: 3868.3926\n",
            "Epoch [47540], val_loss: 3865.3379\n",
            "Epoch [47560], val_loss: 3865.5706\n",
            "Epoch [47580], val_loss: 3860.1416\n",
            "Epoch [47600], val_loss: 3861.0938\n",
            "Epoch [47620], val_loss: 3851.3379\n",
            "Epoch [47640], val_loss: 3857.0793\n",
            "Epoch [47660], val_loss: 3852.7346\n",
            "Epoch [47680], val_loss: 3853.7102\n",
            "Epoch [47700], val_loss: 3854.3684\n",
            "Epoch [47720], val_loss: 3854.7883\n",
            "Epoch [47740], val_loss: 3864.0515\n",
            "Epoch [47760], val_loss: 3865.1633\n",
            "Epoch [47780], val_loss: 3849.2832\n",
            "Epoch [47800], val_loss: 3851.8250\n",
            "Epoch [47820], val_loss: 3863.2278\n",
            "Epoch [47840], val_loss: 3865.2844\n",
            "Epoch [47860], val_loss: 3850.6418\n",
            "Epoch [47880], val_loss: 3861.4905\n",
            "Epoch [47900], val_loss: 3855.8105\n",
            "Epoch [47920], val_loss: 3857.5671\n",
            "Epoch [47940], val_loss: 3863.2410\n",
            "Epoch [47960], val_loss: 3873.7942\n",
            "Epoch [47980], val_loss: 3867.8113\n",
            "Epoch [48000], val_loss: 3854.4446\n",
            "Epoch [48020], val_loss: 3853.2473\n",
            "Epoch [48040], val_loss: 3858.2161\n",
            "Epoch [48060], val_loss: 3858.0042\n",
            "Epoch [48080], val_loss: 3863.3281\n",
            "Epoch [48100], val_loss: 3851.9050\n",
            "Epoch [48120], val_loss: 3853.8503\n",
            "Epoch [48140], val_loss: 3856.2871\n",
            "Epoch [48160], val_loss: 3861.8757\n",
            "Epoch [48180], val_loss: 3857.3533\n",
            "Epoch [48200], val_loss: 3853.9797\n",
            "Epoch [48220], val_loss: 3852.4602\n",
            "Epoch [48240], val_loss: 3858.7566\n",
            "Epoch [48260], val_loss: 3855.2722\n",
            "Epoch [48280], val_loss: 3858.0359\n",
            "Epoch [48300], val_loss: 3861.6873\n",
            "Epoch [48320], val_loss: 3848.7390\n",
            "Epoch [48340], val_loss: 3864.4421\n",
            "Epoch [48360], val_loss: 3857.7214\n",
            "Epoch [48380], val_loss: 3859.3435\n",
            "Epoch [48400], val_loss: 3858.1707\n",
            "Epoch [48420], val_loss: 3857.8313\n",
            "Epoch [48440], val_loss: 3851.7668\n",
            "Epoch [48460], val_loss: 3847.7444\n",
            "Epoch [48480], val_loss: 3853.5793\n",
            "Epoch [48500], val_loss: 3863.0605\n",
            "Epoch [48520], val_loss: 3863.2546\n",
            "Epoch [48540], val_loss: 3855.6975\n",
            "Epoch [48560], val_loss: 3855.6931\n",
            "Epoch [48580], val_loss: 3861.1270\n",
            "Epoch [48600], val_loss: 3858.5247\n",
            "Epoch [48620], val_loss: 3858.3210\n",
            "Epoch [48640], val_loss: 3854.9192\n",
            "Epoch [48660], val_loss: 3865.5811\n",
            "Epoch [48680], val_loss: 3858.5168\n",
            "Epoch [48700], val_loss: 3852.1711\n",
            "Epoch [48720], val_loss: 3860.1516\n",
            "Epoch [48740], val_loss: 3858.5352\n",
            "Epoch [48760], val_loss: 3850.9211\n",
            "Epoch [48780], val_loss: 3852.2219\n",
            "Epoch [48800], val_loss: 3855.4949\n",
            "Epoch [48820], val_loss: 3864.5859\n",
            "Epoch [48840], val_loss: 3866.1482\n",
            "Epoch [48860], val_loss: 3851.1721\n",
            "Epoch [48880], val_loss: 3852.5090\n",
            "Epoch [48900], val_loss: 3859.1699\n",
            "Epoch [48920], val_loss: 3867.2239\n",
            "Epoch [48940], val_loss: 3857.6985\n",
            "Epoch [48960], val_loss: 3856.1365\n",
            "Epoch [48980], val_loss: 3856.3047\n",
            "Epoch [49000], val_loss: 3854.7224\n",
            "Epoch [49020], val_loss: 3862.0984\n",
            "Epoch [49040], val_loss: 3855.4441\n",
            "Epoch [49060], val_loss: 3861.9824\n",
            "Epoch [49080], val_loss: 3850.9512\n",
            "Epoch [49100], val_loss: 3860.9192\n",
            "Epoch [49120], val_loss: 3854.3879\n",
            "Epoch [49140], val_loss: 3861.1277\n",
            "Epoch [49160], val_loss: 3855.7764\n",
            "Epoch [49180], val_loss: 3861.0579\n",
            "Epoch [49200], val_loss: 3850.2078\n",
            "Epoch [49220], val_loss: 3851.4006\n",
            "Epoch [49240], val_loss: 3862.6301\n",
            "Epoch [49260], val_loss: 3849.7664\n",
            "Epoch [49280], val_loss: 3848.7402\n",
            "Epoch [49300], val_loss: 3859.1257\n",
            "Epoch [49320], val_loss: 3851.1895\n",
            "Epoch [49340], val_loss: 3852.8469\n",
            "Epoch [49360], val_loss: 3856.1331\n",
            "Epoch [49380], val_loss: 3861.6267\n",
            "Epoch [49400], val_loss: 3846.6895\n",
            "Epoch [49420], val_loss: 3861.1384\n",
            "Epoch [49440], val_loss: 3855.5986\n",
            "Epoch [49460], val_loss: 3859.9805\n",
            "Epoch [49480], val_loss: 3853.2361\n",
            "Epoch [49500], val_loss: 3847.5020\n",
            "Epoch [49520], val_loss: 3858.3594\n",
            "Epoch [49540], val_loss: 3846.3757\n",
            "Epoch [49560], val_loss: 3856.6191\n",
            "Epoch [49580], val_loss: 3848.7849\n",
            "Epoch [49600], val_loss: 3849.0969\n",
            "Epoch [49620], val_loss: 3856.0251\n",
            "Epoch [49640], val_loss: 3855.2695\n",
            "Epoch [49660], val_loss: 3851.6719\n",
            "Epoch [49680], val_loss: 3857.8789\n",
            "Epoch [49700], val_loss: 3851.2654\n",
            "Epoch [49720], val_loss: 3859.3867\n",
            "Epoch [49740], val_loss: 3849.2571\n",
            "Epoch [49760], val_loss: 3866.0525\n",
            "Epoch [49780], val_loss: 3854.0681\n",
            "Epoch [49800], val_loss: 3862.9697\n",
            "Epoch [49820], val_loss: 3853.6873\n",
            "Epoch [49840], val_loss: 3849.4375\n",
            "Epoch [49860], val_loss: 3857.3352\n",
            "Epoch [49880], val_loss: 3859.0488\n",
            "Epoch [49900], val_loss: 3860.1062\n",
            "Epoch [49920], val_loss: 3847.4890\n",
            "Epoch [49940], val_loss: 3852.2571\n",
            "Epoch [49960], val_loss: 3859.4875\n",
            "Epoch [49980], val_loss: 3861.5842\n",
            "Epoch [50000], val_loss: 3851.3867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm6aiCRmaosf"
      },
      "source": [
        "**Q: What is the final validation loss of your model?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmFBXPZSaosg",
        "outputId": "7d4050f3-f9de-411d-ebac-938e28125ce2"
      },
      "source": [
        "val_loss = evaluate(model, val_loader)\n",
        "val_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_loss': 3851.38671875}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCdUnXfBaosg"
      },
      "source": [
        "Let's log the final validation loss to Jovian and commit the notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNEnFtsfaosg",
        "outputId": "8eacae4f-a4e9-455b-e80a-c138a5fbb115"
      },
      "source": [
        "jovian.log_metrics(val_loss=val_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Metrics logged.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "1GT8WX6iaosg",
        "outputId": "4860f2f7-1547-4b4d-9eaa-29d000b26f2c"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/noumanamir453/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/noumanamir453/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je2fRcaVaosh"
      },
      "source": [
        "## Step 5: Make predictions using the trained model\n",
        "\n",
        "**Q: Complete the following function definition to make predictions on a single input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llEZqXi4aosh"
      },
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(input)                # fill this\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRyCxb4jaosh",
        "outputId": "c77c61b7-c69a-4cc3-f56e-8154d52f81ec"
      },
      "source": [
        "input, target = val_ds[0]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([58.0000,  0.0000, 25.2747,  0.0000,  0.0000])\n",
            "Target: tensor([13845.5254])\n",
            "Prediction: tensor(13698.7568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aueYBcaaosh",
        "outputId": "c4fdafd7-1924-4dd4-f706-3f100211cac4"
      },
      "source": [
        "input, target = val_ds[10]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([49.0000,  1.0000, 40.9035,  0.0000,  0.0000])\n",
            "Target: tensor([9507.1680])\n",
            "Prediction: tensor(10641.6943)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7OxObb8aosh",
        "outputId": "92f38f8b-4e47-4bcc-f380-38d0b668f86e"
      },
      "source": [
        "input, target = val_ds[23]\n",
        "predict_single(input, target, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: tensor([55.0000,  1.0000, 23.8650,  1.0000,  0.0000])\n",
            "Target: tensor([12626.5928])\n",
            "Prediction: tensor(12735.9404)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "4uN8qkYKaosi",
        "outputId": "b6db4fb5-5393-44d9-87f9-14cae4eabfc5"
      },
      "source": [
        "jovian.commit(project=project_name, environment=None)\n",
        "jovian.commit(project=project_name, environment=None) # try again, kaggle fails sometimes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/noumanamir453/02-insurance-linear-regression\u001b[0m\n",
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] Uploading colab notebook to Jovian...\u001b[0m\n",
            "[jovian] Attaching records (metrics, hyperparameters, dataset etc.)\u001b[0m\n",
            "[jovian] Committed successfully! https://jovian.ai/noumanamir453/02-insurance-linear-regression\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://jovian.ai/noumanamir453/02-insurance-linear-regression'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe6y8Bgqaosi"
      },
      "source": [
        "torch.save(model.state_dict(), 'insurance-regression.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}